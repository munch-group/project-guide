[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Title of your project",
    "section": "",
    "text": "Introduction\nThese pages are generated from Git repository (more about that later). The repository serves both as a source of practial information to get you started, and as a scaffold for your project. Once you have copied it and made it your own, you populate with your own text, code, analysis notebooks, and documentation. For now most of what you see are placeholders for what will eventually be your own contributions."
  },
  {
    "objectID": "index.html#project-outline",
    "href": "index.html#project-outline",
    "title": "Title of your project",
    "section": "Project outline",
    "text": "Project outline\nHere you should write a paragraph outlining the project to the extent you can at this point. What are the goals of your project? What would you like to find out? What would you like to learn? You should update it along the way."
  },
  {
    "objectID": "index.html#project-plan",
    "href": "index.html#project-plan",
    "title": "Title of your project",
    "section": "Project plan",
    "text": "Project plan\nHere you should outline project plan and what you intend to do in the weeks/months of your project. This is ofcause tentative and will change along the way. But it is important that it changes because you decide it is meaningful.\n\nThe first month is allocated to …\n\n\n\nThe last month …"
  },
  {
    "objectID": "guides/laptop_setup.html",
    "href": "guides/laptop_setup.html",
    "title": "1  Laptop setup",
    "section": "",
    "text": "You will do your work on our computing cluster, but before we get there, we need to get you properly set up on your own machine.\n\n1.0.1 Install Python\nIf you have not done so already, you should install a distribution of Python called Anaconda. Anaconda is not only an easy way of installing Python on Windows, Mac, and Linux; it also comes with the conda package management system (see below). To install Anaconda, head to this page. When the download has been completed, you must follow the default installation.\n\n\n1.0.2 The Terminal\nMost of the programs we will use in this course are command-line applications. I.e., programs that are executed by writing their name and any arguments in a terminal rather than clicking on an icon and using a graphical user interface. There are many different programs that can serve as a terminal. If you have a Windows machine, you must use the Anaconda Powershell Prompt (not the Anaconda Prompt and not the CMD). You installed Anaconda Powershell Prompt along with Anaconda Python. If you have a Mac, the terminal you will use is called Terminal. The Terminal application is pre-installed on Mac. So from now on, whenever I refer to the terminal, I mean Anaconda Powershell Prompt on Windows and Terminal on Mac. We will assume some familiarity with using a terminal and with executing commands on the command line. If you have not used a terminal before, or if you are a bit rusty, you should run through this primer before you go on.\n\n\n1.0.3 Conda environments\n\nYou need to install packages and programs for use in your analyses and pipelines. Sometimes, however, the versions of packages you need for one project conflicts with the versions you need for other projects that you work on in parallel. Such conflicts seem like an unsolvable problem. Would it not be fantastic if you could create a small world insulated from the rest of your Anaconda installation. Then that small world would only contain the packages you needed for a single project. If each project had its own isolated world, then there would be no such conflicts. Fortunately, there is a tool that lets you do just that, and its name is Conda. The small worlds that Conda creates are called “environments,” and you can create as many as you like. You can then switch between them as you switch between your bioinformatics projects. Conda also downloads and installs the packages for you, and it makes sure that the packages you install in each environment are compatible. It even makes sure that packages needed by packages (dependencies) are installed too. By creating an environment for each project, the libraries installed for each project do not interfere.\n\n\n1.0.4 Create an environment on your local machine\nWhen you install Anaconda or Miniconda, Conda makes a single base environment for you. It is called “base,” and this is why it says “(base)” at your terminal prompt. You need a conda environment for your project on both your local machine and on the cluster. Let us call both of them ‘birc-project’ (you can call it anything you like).\nThe environment on your local machine does not need a lot of packages since it mainly serves to let you connect to the cluster. This creates the environment and installs slurm-jupyter from my conda channel:\nconda create -n birc-project -c kaspermunch slurm-jupyter\nSay yes (press Enter) when asked to install packages.\n\n\n1.0.5 VPN\nTo be able to connect to the cluster, you need to on the AU internal network. You can do that by either physically being on campus or by connecting to the AU network using VPN. To install VPN, use the instructions on this page. Before you can use the VPN, you also need to enable two-step verification. You can see how to do that on the same page. If you are not physically on campus, you need to activate your VPN before you can log in to the cluster. Your password for VPN is the same as you use to log on to access Blackboard."
  },
  {
    "objectID": "guides/genomedk.html",
    "href": "guides/genomedk.html",
    "title": "2  Cluster access",
    "section": "",
    "text": "The GenomeDK cluster is a very large collection of computers with a shared file system. On their homepage your can find lots of useful information about the cluster beyond what is covered on these pages. The cluster does not have a screen and a keyboard you can go use, but by connecting to the cluster from your computer, you can create and edit files much like if they were on your machine. This pages takes you through the steps needed to connect and access the cluster.\n\n\n\n\n\n\nHeads up\n\n\n\nThis is not a leisure read. Make sure you follow it to the letter. Do each step in order and do not proceed untill you have completed each step\n\n\nBelow you will see something like &lt;cluster user name&gt; or &lt;project folder&gt; a lot. When ever you see something like that you should replace the whole thing, including &lt; and &gt;, with whatever is says. E.g., if your cluster user name is preben you should replace &lt;cluster user name&gt; with preben.\nBefore you can begin, you need access to the cluster. The cluster is called GenomeDK and has its own website with lots of information and documentation. To get an account on the cluster, you must request one here. Below, username will represent your user name.\nOn the cluster, you have a home folder that only you have can access. That is where you end up when you log in. Collaborative projects or projects that use or generate a lot of data projects belong in project folders. If you do a project, we will set up a dedicated project folder for this.\nYour project is a research project. Even if it is meant for training, think of it as training reproducibility too. Your efforts, experiences, results, and developed expertise is valuable to all that comes after you. So do not make your project a dead end; make it a shoulder to stand on.\nReproducibility basically means that anyone should be able to do exactly what you did to exactly reproduce your results. They should be able to get the same results in terms of numbers, plots, etc. This requires care and attention to detail, but it is not difficult. This page will help you get set up to do reproducible research.\n\n2.0.1 Connecting to the cluster using ssh\n\nSSH is short for secure shell. A shell is the software that lets you run commands in your terminal window. The secure shell (SSH) lets you securely log in to another computer so you can navigate the folders and run commands on that machine. So when you open your terminal window, your commands run on your local machine, but when you “ssh” (yes it is a verb too) into the cluster, your commands now run on the cluster. Before you go on, try to run the command hostname in you terminal. You can see that it prints something that tells you that you are on your own computer.\nYou connect to the cluster from the terminal by executing this command (remember to replace &lt;cluster user name&gt; with your actual cluster user name):\nssh &lt;cluster user name&gt;@login.genome.au.dk\nWhen you do, you are prompted for the password for your cluster username. Enter that and press enter. You are now in your home folder on the cluster. Your terminal looks the same as before, but it will print:\n  _____                                ______ _   __\n |  __ \\                               |  _  \\ | / /\n | |  \\/ ___ _ __   ___  _ __ ___   ___| | | | |/ /\n | | __ / _ \\ '_ \\ / _ \\| '_ ` _ \\ / _ \\ | | |    \\\n | |_\\ \\  __/ | | | (_) | | | | | |  __/ |/ /| |\\  \\\n  \\____/\\___|_| |_|\\___/|_| |_| |_|\\___|___/ \\_| \\_/\nIf you run the hostname command again, you can see that you are on fe-open-01. Now log out of the cluster again. You do that using the exit command or by pressing Ctrl-d. Now you are back on your own machine. Try hostname again and see what your own machine is called.\nYou will need to log in to the cluster many many times, so you should set up your ssh connection to the cluster so you can connect securely without typing the password every time. You do not need to know how this works, but if you are interested, here is roughly how:\n\n\n\n\n\n\nSSH keys\n\n\n\nFirstly, you have to understand what public/private encryption keys are. A private key is a very long, random sequence of bits. A private key is kept secret and never leaves your own machine. A public key is another string of bits that is a derivative of the private key. You can generate a unique public key from the private key but cannot get the private key from a public key: It is a one-way process. Using the public key, you can encrypt (or sign) any message, and it will only be possible to decrypt it using the private key. In other words, anyone with your public key can send you encrypted messages that only you will be able to read. So, if the cluster has your public key saved, it can authenticate you like this: The cluster sends your machine a message that is encrypted using your public key. Your machine then decrypts the message using its private key and sends it back. If the cluster agrees it is decrypted correctly, it logs you in.\n\n\nFirst, check if you have these two authentication files on your local machine (you can do so by running ls -a ~/.ssh in the terminal):\n~/.ssh/id_rsa\n~/.ssh/id_rsa.pub\nYou most likely do not. If so, you generate a pair of authentication keys with the command below. Just press Enter when asked “Enter file in which to save the key”. Do not enter a passphrase when prompted - just press enter:\nssh-keygen -t rsa\nNow use ssh to create a directory ~/.ssh on the cluster (assuming your username on the cluster is &lt;cluster user name&gt;). You will be prompted for your password.\nssh &lt;cluster user name&gt;@login.genome.au.dk mkdir -p .ssh\nFinally, append the public ssh key on your local machine to the file .ssh/authorized_keys on the cluster and enter your password (replace &lt;cluster user name&gt; with your cluster user name):\ncat ~/.ssh/id_rsa.pub | ssh username@login.genome.au.dk 'cat &gt;&gt; .ssh/authorized_keys'\nFrom now on, you can log into the cluster from your local machine without being prompted for a password.\nTry it:\nssh &lt;cluster user name&gt;@login.genome.au.dk\n(see, no password)."
  },
  {
    "objectID": "guides/cluster_setup.html#install-python-on-your-cluster-account",
    "href": "guides/cluster_setup.html#install-python-on-your-cluster-account",
    "title": "3  Cluster set up",
    "section": "3.1 Install Python on your cluster account",
    "text": "3.1 Install Python on your cluster account\nYou need to install miniconda (a minimal Anaconda version) in your cluster home dir. Log in to the cluster and run this command to download the miniconda install script:\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nThen use this command to download and install miniconda:\nbash Miniconda3-latest-Linux-x86_64.sh\nFollow the default installation, and say yes when it asks you if it should run conda init for you.\nNP: Now log out of the cluster and log back in. This is needed to make the conda command available to you."
  },
  {
    "objectID": "guides/cluster_setup.html#the-project-folder",
    "href": "guides/cluster_setup.html#the-project-folder",
    "title": "3  Cluster set up",
    "section": "3.2 The project folder",
    "text": "3.2 The project folder\nThe project folder is a folder that is set up on the cluster to hold your project. I call it projectfolder here, but it will be called something sensible like baboonadmixture.\nIt is accessible to only you and anyone else you collaborate with (such as your supervisor). The project folder is in your home directory and should hold the following subfolders:\nprojectfolder\n    /data\n    /people\n        /username\n        /supervisor_username\nThe &lt;projectfolder&gt;/people/&lt;username&gt; is your domain. This is where you have all the files that relates to your project.\nThe name of the project folder is is also the name of the account that gets billed for the work on the cluster. When you run srun, sbatch or slurm-jupyter you must specify that project name using the -A or --account options (see below for more details on that).\n\n3.2.1 Cloning this git repository to the cluster\nGo to your folder under the project folder (&lt;projectfolder&gt;/people/&lt;username&gt;) and clone your repository:\ngit clone git@github.com:username/birc-project.git\n(replace username with your GitHub username).\nYou now have a folder called &lt;projectfolder&gt;/people/&lt;username&gt;/birc-project and this is where you will do all your work for the project.\nIf you cd into birc-directory and run ls, you will see a number of folders.\n\ndata: Stores small (tens of megabases) data files you want to keep .\nbinder: Stores the environment.yml files documenting your conda environment used in the project.\nsandbox: Stores experiment and other files that are not yet part of your project workflow. This keeps the rest of the folder structure clean.\nscripts: Stores Python scripts that that produces intermediate and final results.\nsteps: Stores intermediary files (“steps” on the way to final results).\nnotebooks: Stores Juptyer notebooks with code, documentation, and results.\nfigures: Stores result plots and figures you make.\nresults: Stores the small result files of your project (tens of megabases).\n\nFiles in all those folders are under Git control, except files in the steps folder. Those files are not backed up in any way, but should instead be reproducible using the code and information in your other folders."
  },
  {
    "objectID": "guides/cluster_setup.html#the-github-repository",
    "href": "guides/cluster_setup.html#the-github-repository",
    "title": "3  Cluster set up",
    "section": "3.3 The GitHub repository",
    "text": "3.3 The GitHub repository\n\nThe text you are reading now is actually in a Git repository i made for you.\nGit is a version control tool that you use from the terminal. A folder under Git control is called a repository. Git does not interfere with your files and it does not save them. It lets you monitor the state of your files so you can easily see if any files are added, modified, or removed, and it allows you to (manually) maintain a record of what files where changes when, how, and for what reason.\nIn addition to the documentation you are reading now, the repository serves as a template for your project. Follow these steps in order to get this repository:\n\nStart by creating your own github account if you do not have one.\nFollow the instructions on this page to add ssh keys to GitHub.\nLog in to your GitHub account on the web. Go to the analysis-remplate-repo. Click the big green button that says “Use this template” and pick “Create new repository”. You are then prompted for a name for your repository. Name it birc-project. Leave the rest as it is and click “Create repository”. This will create your own copy of this repository on your own GitHub account.\n\nOnce your own birc-project repository is ready, find it on your own account, go to the repository front page. Look at the cluster_setup.qmd file in the guides folder. This is what renders into the page you are reading this from. You will learn later how to make such web pages yourself to document your work."
  },
  {
    "objectID": "guides/cluster_setup.html#git-1.0.1",
    "href": "guides/cluster_setup.html#git-1.0.1",
    "title": "3  Cluster set up",
    "section": "3.4 Git 1.0.1",
    "text": "3.4 Git 1.0.1\nStart logging into the cluster and run these two commands to let Git know who you are:\ngit config --global user.name \"&lt;Your GitHub user name&gt;\"\ngit config --global user.email &lt;your_email@whatever.com&gt;\nNote that to run git commands tracking your birc-project, .\nThese tutorials are good. The three most important commands to learn are git status, git add, git rm, git commit and git push.\nYou should read the documentation, but in a nutshell this is how it works:\ngit status shows you the status of your files. It may show you that you have created or modified one or more files.\n\n\n\n\n\n\nTip\n\n\n\nWhen you run git commands, you must be in your birc-project folder. Otherwise git will not know which repository you are referring to.\n\n\nTo journal the creation or modification of a file, you run git add &lt;the_changed_file&gt;. This “stages” the change. This adds the file to the a “group” of changes that represent some modification to your project. You can add more files to that “group” by running git add again.\nMaybe you added two python files that together lets you run some analysis. Now you want to store the group of changes to the journal maintained by Git and associate it with a description that describes it. For that you use git commit -m 'description'. If you added two python files, your description could be 'Added two python files for my analysis'. Now your changes are recorded in the Git journal for the birc-project repository on the cluster, but that does not serve as a backup in case you accidentally delete your entire folder or the cluster burns down.\nTo backup your repository you need to synchronize your local birc-project repository on your computer with the birc-project repository on GitHub. You do that using the git push command.\nThere is a cheat sheet here and some good visual guides here and here.\n\n\n\n\n\n\nWarning: Files on the cluster are not backed up!\n\n\n\nYour files on the cluster are not backed up! If you want to backup files, you need to put them in a folder called BACKUP. But even if you do you may loose a week of work, since the backup loop is very slow.\n\n\nThe best/only way to keep your code safe is to track your files with git push each set of changes to GitHub as often as it makes sense. The more often you do it, the less work you will loose if you accidentally delete or overwrite a file.\nWe will get back to which files you should track using Git in Chapter 4 on reproducible research."
  },
  {
    "objectID": "guides/cluster_setup.html#create-a-conda-environment",
    "href": "guides/cluster_setup.html#create-a-conda-environment",
    "title": "3  Cluster set up",
    "section": "3.5 Create a conda environment",
    "text": "3.5 Create a conda environment\nLog in to the cluster and run this command to create a conda environment for your project on the cluster. This environment should contain the packages that you need for your project.\nCreate your environment like this:\nconda env create -y -f binder/environment.yml\nYou probably end up needing more packages than is initially included, you can easily install them later. E.g., to see how to install biopython using conda, just google “conda biopython”. The top link instructs you to install it like this: conda install -c conda-forge biopython.\nImportant: Whenever you log into the cluster to work on your project, you should activate your birc-project environment like this:\nconda activate birc-project\nWhen your environment is active, it says (birc-project) on the command prompt instead of (base).\n\n3.5.1 Set up Jupyter\n\nJupyter is a notebook environment where you can easily combine text, code, and plots. Using the slurm-jupyter tool, you can run a jupyter notebook on the cluster but see it in the browser on your own machine. That way, your analysis runs on the cluster file system where your data is but the notebook interface is sent to your browser window.\nBefore you can connect to a jupyter session on the cluster, you need to do a bit of configuration of the jupyter settings on the cluster. slurm-jupyter comes with script that automates that procedure. Just log into the cluster, activate your environment, and run:\nconfig-slurm-jupyter.sh\nThe script will ask for a lot of information. You can just press Enter for all of them except when prompted for what password you want to use: Then, you must type your cluster password.\n\n\n3.5.2 Visual Studio Code\n\nIf you did not do so when you installed Anaconda, you should download and install Visual Studio Code. VScode is great for developing scripts and editing text files. Once you have installed VS code, you should install the “Remote Development” extension. You do that by clicking the funny squares in the left bar and search for “Remote Development”. Once installed, you can click the small green square in the lower-left corner to connect to the cluster. Select “Connect current window to host” then “Add new SSH host”, then type &lt;username&gt;@login.genome.au.dk, then select the config file .ssh/config. Now you can click the small green square in the lower-left corner to connect to the cluster by selecting login.genome.au.dk. It may take a bit, but once it is done installing a remote server, you will have access to the files in your home folder on the cluster.\n\n\n3.5.3 How to run a Jupyter notebook on the cluster\nJupyter runs best in the Chrome browser or Safari on Mac. For the best experience, install that before you go on. It does not need to be your default browser. slurm-jupyter will use it anyway. Now make sure you are on your own machine and that your popgen environment is activated. Then run this command to start a jupyter notebook on the cluster and send the display to your browser:\nslurm-jupyter -C -u &lt;cluster_user_name&gt; -A &lt;projectfolder&lt;&gt; -e birc-project\n(replace &lt;cluster_user_name&gt; with your cluster user name, &lt;projectfolder&gt; with your project folder name.\nWatch the terminal to see what is going on. After a while, a jupyter notebook should show up in your browser window. The first time you do this, your browser may refuse to show jupyter because the connection is unsafe. In Safari you are prompted with this winidow where you click “details”:\n\nThen you get this window and click “visit this website”:\n\nIn Chrome, you can simply type the characters “thisisunsafe” while in the Chrome window:\n\nOnce ready, jupyter may ask for your cluster password. To close the jupyter notebook, press Ctrl-c in the terminal. Closing the browser window does not close down the jupyter on the cluster. You can read this tutorial to learn how to use a jupyter notebook.\n\n\n3.5.4 Running interactive commands on the cluster\nWhen you log into the cluster, you land on the “front-end” of the cluster. Think of it as the lobby of a giant hotel. If you execute the hostname command, you will get fe-open-01. fe1 is the name of the front-end machine. The “front-end” is a single machine shared by anyone who logs in. So you cannot run resource-intensive jobs there, but quick commands are ok. Commands that finish in less than ten seconds are ok. In the exercises for this course, you will run software that takes a much longer time to finish. So you need one of the computing machines on the cluster, so you can work on that instead. You ask for a computing machine by running this command:\nsrun --mem-per-cpu=1g --time=3:00:00 --account=&lt;projectfolder&gt; --pty bash\nThat says that you need at most one gigabyte of memory, that you need it for at most three hours (the duration of the exercise), and that the computing expenses should be billed to the project &lt;projectfolder&gt;. When you execute the command, your terminal will say “srun: job 40924828 queued and waiting for resources”. That means that you are waiting for a machine. Once it prints “srun: job 40924828 has been allocated resources”, you have been logged into a computing node. If you execute the hostname command, you will get something like s05n20. s05n20 is a computing machine. The same way you moved from your own computer to front-end machine of the cluster by logging in using ssh, the command above moves you from the front-end to a compute machine. Now you can execute any command you like without causing trouble for anyone.\nNow try to log out of the compute node by executing the exit command or by pressing Ctrl-d. If you execute the hostname command again, you will get fe1.genomedk.net showing that you are back at the front-end machine.\n\n\n3.5.5 Queueing commands on the cluster\nFor non-interactive work, it is better to submit your command as a job to the cluster. When you do that, the job gets queued along with many other jobs, and as soon as the requested resources are available on the cluster, the job will start on one the many many machines. To submit a job, you must first create a file (a “batch script”) that contains both the requested computer resources and the command you want to run.\nCreate a file called myscript.sh with exactly this content:\n#!/bin/bash\n#SBATCH --mem=1gb\n#SBATCH --time=01:00:00\n#SBATCH --account=&lt;projectfolder&gt;\n#SBATCH --job-name=firstjob\n\necho \"I can submit cluster jobs now!\" &gt; success.txt\n(replace &lt;projectfolder&gt; with your project folder name)\nThe first line says this is a bash script, the lines following three lines say that your job needs at most one gigabyte of memory, will run for at most one hour, that the expenses should be billed to the project &lt;projectfolder&gt;. The fourth line gives the name of the job. Here we have called it firstjob, but you should name it something sensible.\nYou submit the job using the sbatch command:\nsbatch myscript.sh\nNow your job is queued. Use the mj command to see what jobs you have queued or running. That will show something like this:\n                                                                        Alloc\nJob ID           Username Queue    Jobname    SessID NDS  S Elap Time   nodes\n---------------- -------- -------- ---------- ------ ---  - ----------  -----\n34745986         kmt      normal   firstjob       --   1  R 0-00:19:27  s03n56\nIf you want to cancel this job before it finishes, you can use the scancel command:\nscancel 34745986\nOnce your job finishes, it has created the file success.txt and written “I can submit cluster jobs now!” to it. So see that you can use the cat command:\ncat success.txt\nWhen you a program or script on the command line, it usually also prints some information in the terminal. When you run a job on the cluster there is no terminal to print to. Instead, this is written to two files that you can read when the job finishes. In this case, the fiels are called firstjob.stdout and firstjob.stderr. To see what is in them, you can use the cat command:\ncat firstjob.stdout\nand\ncat firstjob.stderr\nThat is basically it.\n\n\n3.5.6 How to copy files to and from the cluster\nYou may need to transfer files back and forth between your own machine and the cluster. To copy a file called file in a directory called dir on the cluster to the current folder on your own machine, you can use the scp command:\nscp &lt;cluster_user_name&gt;@login.genome.au.dk:dir/file .\nTo copy a file called file in the current folder on your own machine to a folder called dir on the cluster, you do this:\nscp ./file &lt;cluster_user_name&gt;@login.genome.au.dk:dir/"
  },
  {
    "objectID": "guides/reproducible.html#specify-raw-input-data",
    "href": "guides/reproducible.html#specify-raw-input-data",
    "title": "4  Reproducible research",
    "section": "4.1 Specify raw input data",
    "text": "4.1 Specify raw input data\nReport the location and version of the raw data that serve as input to your analysis. Make sure this data is “read only” so that onone accidentally modifies or deletes it. You can do that like this:\nchmod a=r important_input_file.txt\nor recursively for an entire folder:\nchmod -R a=r input_file_folder"
  },
  {
    "objectID": "guides/reproducible.html#define-dependencies",
    "href": "guides/reproducible.html#define-dependencies",
    "title": "4  Reproducible research",
    "section": "4.2 Define dependencies",
    "text": "4.2 Define dependencies\nEmploying tools like Conda define the dependencies of your of your project, ensuring that others can run the same code with the same dependencies.\nWhen you create your conda environment, and whenever you install new packages, you should update the environment.yml file in the binder directory. That way the specification of your environment is always up to date and allows anyone to create the conda environment required to run your analysis You do it by running this command:\nconda env export --from-history -f ./binder/environment.yml"
  },
  {
    "objectID": "guides/reproducible.html#use-version-control",
    "href": "guides/reproducible.html#use-version-control",
    "title": "4  Reproducible research",
    "section": "4.3 Use version control",
    "text": "4.3 Use version control\nUsing version control systems like Git to track changes to code and documentation over time. This helps in understanding the evolution of the research and facilitates collaboration. It also allows you to tag the the state of your repository upon publication, so you can keep working on it later without disrupting its state at publication.\nIn the world of data projects, there are three kinds of data files.\nType 1 files: Files representing the input to your project: sequencing reads, genomes, genotypes, etc. These are usually difficult or expensive to reproduce and once made they never change. They are often too large to fit on GitHub, so they are saved (and backed up) indefinitely on the cluster, and can be distributed upon request to other researchers that want to replicate your analysis. Often the data is only local copy of data also available in a public database. You can put such files in the data folder of your repository on the cluster, but unless they are very small, do not git add these files to Git control.\nType 2 files: Files representing your work and the results from the project: documentation, scripts, code, gwf workflows, notebooks, plots, tables, etc. These files are usually as small as they are precious and they are the ones you add to your Git repository and puth to GitHub every time you change them. These files are workflow.py, and files you put in the binder, scripts, notebooks, results, figures, and reports folders.\nType 3 files: Files representing intermediary steps to get from files of type 1 to files of type 2. These can be large and many and often most of the harddisk space consumed by your project. However, they are easily regenerated if your project is reproducible. So type 3 files need not be saved indefinitely and they should not be added to your Git repository. In fact, type 3 files should be deleted as soon as the project is finished. All such files must be put in the steps folder or in folders inside the steps folder. This way, removing all type 3 files is safely done by deleting the content of the steps folder."
  },
  {
    "objectID": "guides/reproducible.html#make-computatioal-steps-an-executable-workflow",
    "href": "guides/reproducible.html#make-computatioal-steps-an-executable-workflow",
    "title": "4  Reproducible research",
    "section": "4.4 Make computatioal steps an executable workflow",
    "text": "4.4 Make computatioal steps an executable workflow\nhttps://gwf.app/\nPipeline the steps of the computationally demanding part of your analysis in executable workflows using cluster workflow tools like GWF. This ensures that interdependent steps are run in the right order and rerun if necessary."
  },
  {
    "objectID": "guides/reproducible.html#make-your-analysis-executable",
    "href": "guides/reproducible.html#make-your-analysis-executable",
    "title": "4  Reproducible research",
    "section": "4.5 Make your analysis executable",
    "text": "4.5 Make your analysis executable\nUse Jupyter notebooks to assemble the code, ducumentation, and figures relevant to each part of your subsequent analysis. That way your analysis is what is produced by running your notebooks in order, no more, no less. placeholder notebooks in the notebooks folder\nname them so they sort lexicographically: 01_first_analysis.ipynb, 02_second_analysis.ipynb."
  },
  {
    "objectID": "guides/reproducible.html#make-your-reporting-executable",
    "href": "guides/reproducible.html#make-your-reporting-executable",
    "title": "4  Reproducible research",
    "section": "4.6 Make your reporting executable",
    "text": "4.6 Make your reporting executable\nCompile your manuscript and any supplementary ducumemnts by linking to figures and results in your notebooks. This is easily done using tools like Quarto\nMarkdown / Qmarkdown / Notebooks\nthe _quarto.yml file\nrendering\nat the project end set output-dir to docs, render the whole thing and add docs to repository"
  },
  {
    "objectID": "guides/reproducible.html#make-your-entire-project-publicly-available",
    "href": "guides/reproducible.html#make-your-entire-project-publicly-available",
    "title": "4  Reproducible research",
    "section": "4.7 Make your entire project publicly available",
    "text": "4.7 Make your entire project publicly available\nMaking your repository publically available on GitHub. In addition to the scientific reguirement, reproducibility allows anyone to benefit from and build upon your work, greatly increasing its value."
  },
  {
    "objectID": "guides/reproducible.html#reproducing-your-work",
    "href": "guides/reproducible.html#reproducing-your-work",
    "title": "4  Reproducible research",
    "section": "4.8 Reproducing your work",
    "text": "4.8 Reproducing your work\nIf you follow the steps above, reproducing your results would only entail the following steps:\n\nRetrieve the raw data in the specified version.\nClone your Git repository.\nCreate the conda environment from the environment.yml file.\nRun GWF workflow on a compute cluster for the computationally demanding parts of your analysis.\nRun the Jupyter notebooks in the specified order.\nRun Quarto on the resulting state of the repository to build the manuscript and supplementary information.\n\nBelow I will go over how to organize your project so that these steps also contribute to makeing your own life easier."
  },
  {
    "objectID": "notebooks/01_notebook.html",
    "href": "notebooks/01_notebook.html",
    "title": "5  Some analysis",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nsns.set_style(\"whitegrid\")\nimport random\n\n\nplt.plot([random.random() for i in range(100)]) ;\n\n\n\n\nFigure 5.1: Line plot of random points. bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla"
  },
  {
    "objectID": "notebooks/02_notebook.html",
    "href": "notebooks/02_notebook.html",
    "title": "6  Some other analysis",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nsns.set_style(\"whitegrid\")\nimport random\n\n\nplt.scatter([random.random() for i in range(100)],\n            [random.random() for i in range(100)]) ;\n\n\n\n\nFigure 6.1: Scatter plot of random points"
  },
  {
    "objectID": "reports/manuscript.html#abstract",
    "href": "reports/manuscript.html#abstract",
    "title": "7  Manuscript",
    "section": "7.1 Abstract",
    "text": "7.1 Abstract\nbla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla"
  },
  {
    "objectID": "reports/manuscript.html#introduction",
    "href": "reports/manuscript.html#introduction",
    "title": "7  Manuscript",
    "section": "7.2 Introduction",
    "text": "7.2 Introduction\nbla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla"
  },
  {
    "objectID": "reports/manuscript.html#results",
    "href": "reports/manuscript.html#results",
    "title": "7  Manuscript",
    "section": "7.3 Results",
    "text": "7.3 Results\nbla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla (Figure 7.1).\n\n\n\n\n\n\nFigure 7.1: Line plot of random points. bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n\n\n\n\nSource: 01_notebook.ipynb\nbla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla (Figure 7.2)\n\n\n\n\n\n\nFigure 7.2: Scatter plot of random points\n\n\n\n\nSource: 02_notebook.ipynb"
  },
  {
    "objectID": "reports/manuscript.html#discussion",
    "href": "reports/manuscript.html#discussion",
    "title": "7  Manuscript",
    "section": "7.4 Discussion",
    "text": "7.4 Discussion\nbla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla"
  },
  {
    "objectID": "reports/manuscript.html#methods",
    "href": "reports/manuscript.html#methods",
    "title": "7  Manuscript",
    "section": "7.5 Methods",
    "text": "7.5 Methods\nbla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla"
  },
  {
    "objectID": "reports/supplementary.html",
    "href": "reports/supplementary.html",
    "title": "8  Supplementary info",
    "section": "",
    "text": "bla bla bla"
  }
]