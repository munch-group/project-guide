[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Project Guide",
    "section": "",
    "text": "Introduction\nThese pages serve as a source of practial information to get you started. The part called “Project setup”, take you though the steps to get you set up on your own machine and on our computing cluster. You should go through this part in the other it is listed and make sure you have succesfully completed each step before you go on.\nThe Quickstarts are introductions to the most important tools you will use.\nYou will end up producing a set of pages much like these, and the Notebooks and Reporting both serve as showcases and to give you an idea of how your own notebooks and reports will show once you get to that point."
  },
  {
    "objectID": "index.html#suggested-reading",
    "href": "index.html#suggested-reading",
    "title": "Project Guide",
    "section": "Suggested reading",
    "text": "Suggested reading\nThese are some suggestions for background reading. If you want to some reading before you begin the project, focus on textbook population genetic basics. I will guide you to more relevant reads once you get started.\n\nNielsen and Slatkin’s “An Introduction to Population Genetics: Theory and Applications” is a good introduction to the basics of population genetics.\nGraham Coop’s Lecture notes are also a good basic introduction (and is free).\nGenetic Villains: Killer Meiotic Drivers, is a review on meiotic drive.\nExtraordinary selection on the human X chromosome associated with archaic admixture is our most recent paper on the topic."
  },
  {
    "objectID": "guides/laptop_setup.html",
    "href": "guides/laptop_setup.html",
    "title": "1  Laptop setup",
    "section": "",
    "text": "You will work on our computing cluster, but before we get there, we must get you properly set up on your machine.\n\n1.0.1 Install Python\nIf you have not done so already, you should install a distribution of Python called Anaconda. Anaconda is not only an easy way of installing Python on Windows, Mac, and Linux; it also comes with the conda package management system (more about that later). To install Anaconda, visit this page. When the download completes, you must follow the default installation.\n\n\n1.0.2 The Terminal\nThe programs you will use in the project are command-line applications. I.e., programs executed by writing their name and any arguments in a “terminal” rather than clicking on an icon and using a graphical user interface. Many different programs can serve as a terminal.\n\nIf you have a Windows machine, use the Anaconda Powershell Prompt (not the Anaconda Prompt and not the CMD). You installed Anaconda Powershell Prompt along with Anaconda Python.\nIf you have a Mac, the terminal you will use is called Terminal. The Terminal application is pre-installed on Mac.\n\nFrom now on, whenever I refer to the terminal, I mean Anaconda Powershell Prompt on Windows and Terminal on Mac. I will assume some familiarity with using a terminal and executing commands on the command line. If you have not used a terminal before, or if you are a bit rusty, you should run through this primer before you go on.\n\n\n1.0.3 Conda environments\n\nYou must install packages and programs for your analyses and pipelines. Sometimes, however, the packages you need for one project conflict with the ones you need for other projects you work on in parallel. Such conflicts seem like an unsolvable problem. Would it not be fantastic if you could create a small world insulated from the rest of your Anaconda installation? Then, that small world would only contain the packages you needed for a single project. If each project had its isolated world, then there would be no such conflicts.\nFortunately, a tool lets you do just that, and its name is Conda. Conda’s small worlds are called “environments,” and you can create as many as you like. You can then switch between them as you switch between your bioinformatics projects. Conda also downloads and installs the packages for you, ensuring that the packages you install in each environment are compatible. It even makes sure to install packages (dependencies) required by the packages you install. By creating an environment for each project, the libraries installed for each project do not interfere.\n\n\n1.0.4 Create a conda environment on your local machine\nWhen you install Anaconda or Miniconda, Conda makes a single base environment. It is called “base,” and this is why it says “(base)” at your terminal prompt. You need a conda environment for your project on your local machine. You can call it anything you like, but if you call it birc-project, it will match the rest of this tutorial. So do that.\nThe environment on your local machine only needs a few packages since it only connects you to the cluster. The command below creates a birc-project environment and installs the slurm-jupyter package from my conda channel:\nconda create -y -n birc-project -c kaspermunch slurm-jupyter\nTo activate the environment, use this command:\nconda activate birc-project\nNote how the environment name at your terminal prompt changes from (base) to (birc-project). To deactivate the environment, use this command:\nconda deactivate\nand the terminal prompt changes back to (base).\n\n\n1.0.5 VPN\nYou can only connect to the cluster on the University’s internal network. So you must be physically on campus or use the University’s VPN. To install VPN, follow the instructions on this page. Before you can use the VPN, you also need to enable two-step verification. You can see how to do that on the same page. If you are not physically on campus, you must activate your VPN before logging in to the cluster. Your password for the VPN is the same as the one you use to log on to access Blackboard."
  },
  {
    "objectID": "guides/cluster_access.html",
    "href": "guides/cluster_access.html",
    "title": "2  Cluster access",
    "section": "",
    "text": "Saved\n\nThe GenomeDK cluster is a huge collection of computers with a shared file system. You can find lots of helpful information about the cluster on their homepage beyond what I cover on these pages. The cluster does not have a screen or keyboard you can use, but by connecting to the cluster from your computer, you can create and edit files much like if they were on your laptop. These pages take you through the steps to connect and access the cluster.\n\n\n\n\n\n\nHeads up\n\n\n\nThis is not a leisure read. Make sure you follow it to the letter. Do each step in order, and do not proceed until you have completed each step.\n\n\nBelow, you will see something like &lt;cluster user name&gt; or &lt;project folder&gt;. Whenever you see something like that, you should replace everything, including &lt; and &gt;, with whatever it says. E.g., if your cluster user name is mike, you should replace &lt;cluster user name&gt; with mike.\nBefore you can begin, you need access to the cluster. The cluster is called GenomeDK and has its own website with lots of information and documentation. To get an account on the cluster, you must request one here. Below, &lt;username&gt; will represent your user name.\n\n2.0.1 Connecting to the cluster using ssh\n\nSSH is short for secure shell. A shell is the software that lets you run commands in your terminal window. The secure shell (SSH) allows you to log in to another computer to navigate the folders and run commands on that machine. So when you open your terminal window, your commands run on your local machine, but when you “ssh” (yes, it is a verb, too) into the cluster, your commands run on the cluster. Before you go on, try to run the command hostname in your terminal. You can see that it prints something that tells you that you are on your laptop.\nYou connect to the cluster from the terminal by executing the command below (remember to replace &lt;cluster user name&gt; with your actual cluster user name):\nssh &lt;cluster user name&gt;@login.genome.au.dk\nWhen you do, ssh prompts you for the password that goes with your cluster username (GenomeDK requires two-factor authentication and will sometimes ask you for a site key). Enter the password and press Enter. You are now in your home folder on the cluster. Your terminal looks the same as before, but it will print:\n\n  _____                                ______ _   __\n\n |  __ \\                               |  _  \\ | / /\n\n | |  \\/ ___ _ __   ___  _ __ ___   ___| | | | |/ /\n\n | | __ / _ \\ '_ \\ / _ \\| '_ ` _ \\ / _ \\ | | |    \\\n\n | |_\\ \\  __/ | | | (_) | | | | | |  __/ |/ /| |\\  \\\n\n  \\____/\\___|_| |_|\\___/|_| |_| |_|\\___|___/ \\_| \\_/\n\nIf you run the hostname command again, you can see that you are now on fe-open-01. Now log out of the cluster again by typing exit and Enter (or pressing Ctrl-d). You are now back on your laptop. Try hostname again and see the name of your computer.\nYou will need to log in to the cluster many times, so you should set up your SSH connection to the cluster so you can connect securely without typing the password every time. You do not need to know how this works, but if you are interested, here is roughly how:\n\n\n\n\n\n\nSSH keys\n\n\n\nFirstly, you have to understand what public/private encryption keys are. A private key is a very long, random sequence of bits. A private key is kept secret and never leaves your laptop. A public key is another string of bits that is a derivative of the private key. You can generate a unique public key from the private key but cannot get the private key from a public key: It is a one-way process. You can encrypt (or sign) any message using the public key, and it will only be possible to decrypt it using the private key. In other words, anyone with your public key can send you encrypted messages that only you will be able to read. So, if the cluster has your public key saved, it can authenticate you like this: The cluster sends your machine an encrypted message using your public key. Your laptop then decrypts the message using its private key and sends it back. The cluster then checks the decryption and logs you in.\n\n\nFirst, check if you have these two authentication files on your local machine (you can do so by running ls -a ~/.ssh in the terminal):\n~/.ssh/id_rsa\n~/.ssh/id_rsa.pub\nYou most likely do not. If so, you generate authentication keys with the command below. Just press Enter when prompted for a file in which to save the key. Do not enter a passphrase when prompted - just press enter:\nssh-keygen -t rsa\nNow use ssh to create a directory ~/.ssh on the cluster (assuming your username on the cluster is &lt;cluster user name&gt;). SSH will prompt you for your password.\nssh &lt;cluster user name&gt;@login.genome.au.dk mkdir -p .ssh\nFinally, append the public ssh key on your local machine to the file .ssh/authorized_keys on the cluster and enter your password (replace &lt;cluster user name&gt; with your cluster user name):\ncat ~/.ssh/id_rsa.pub | ssh username@login.genome.au.dk 'cat &gt;&gt; .ssh/authorized_keys'\nFrom now on, you can log into the cluster from your local machine without being prompted for a password.\nTry it:\nssh &lt;cluster user name&gt;@login.genome.au.dk\n(see, no password)."
  },
  {
    "objectID": "guides/cluster_setup.html#install-python-on-your-cluster-account",
    "href": "guides/cluster_setup.html#install-python-on-your-cluster-account",
    "title": "3  Cluster set up",
    "section": "3.1 Install Python on your cluster account",
    "text": "3.1 Install Python on your cluster account\nYou need to install miniconda (a minimal Anaconda version) in your cluster home dir. Log in to the cluster and run this command to download the miniconda install script:\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nThen use this command to download and install miniconda:\nbash Miniconda3-latest-Linux-x86_64.sh\nFollow the default installation, and say yes when it asks you if it should run conda init for you.\nNP: Now log out of the cluster and log back in. This is needed to make the conda command available to you."
  },
  {
    "objectID": "guides/cluster_setup.html#the-project-folder",
    "href": "guides/cluster_setup.html#the-project-folder",
    "title": "3  Cluster set up",
    "section": "3.2 The project folder",
    "text": "3.2 The project folder\nThe project folder is a folder that is set up on the cluster to hold your project. I use the placeholder &lt;projectfolder&gt; here, but it will be called something sensible like baboonadmixture.\nIt is accessible to only you and anyone else you collaborate with (such as your supervisor). The project folder is in your home directory and should hold the following subfolders:\n&lt;projectfolder&gt;\n    /data\n    /people\n        /&lt;username&gt;\n        /&lt;supervisor_username&gt;\nThe &lt;projectfolder&gt;/people/&lt;username&gt; is your domain. This is where you have all the files that relates to your project.\nThe name of the project folder is is also the name of the account that gets billed for the work on the cluster. When you run gwf, srun, sbatch or slurm-jupyter (see below) you must specify that project name using the -A or --account options (see below for more details on that)."
  },
  {
    "objectID": "guides/cluster_setup.html#make-a-git-repository-for-your-project",
    "href": "guides/cluster_setup.html#make-a-git-repository-for-your-project",
    "title": "3  Cluster set up",
    "section": "3.3 Make a Git repository for your project",
    "text": "3.3 Make a Git repository for your project\n\nGit is a version control tool that you use from the terminal. A folder under Git control is called a repository. Git does not interfere with your files and it does not save them. It lets you monitor the state of your files so you can easily see if any files are added, modified, or removed, and it allows you to (manually) maintain a record of what files where changes when, how, and for what reason.\n\nStart by creating your own github account if you do not have one already.\nFollow the instructions on this page to add ssh keys to GitHub.\nEmail me your GitHub username on so I can add you to the shared GitHub account for our research group. I will create a repository for you with scaffold of folders and with placeholder files that will get you started in the right way.\nWait for an email or notification and accept my inviation to the “munch-lab” GitHub organization and an email from me with the name of the repository I made for your project. In what follows, I will use &lt;repositoryname&gt; for the name of your repository.\nMake sure you are logged into your GitHub account and then go to the repository listing at the munch-lab organization on GitHub. Find the directory I made for you and have a look at what is in there. Leave it there for now.\n\n\n3.3.1 Cloning this git repository to the cluster\nStart logging into the cluster and run these two commands to let Git know who you are:\ngit config --global user.name \"&lt;Your GitHub user name&gt;\"\ngit config --global user.email &lt;your_email@whatever.com&gt;\nGo to your folder under the project folder (~/&lt;projectfolder&gt;/people/&lt;username&gt;). Once you are in that folder, you can “clone” your git repository from GitHub to the folder on the cluster.\ngit clone git@github.com:munch-lab/&lt;repositoryname&gt;.git\n(replace &lt;repositoryname&gt; with the actual name of your repository).\nYou now have a folder called &lt;projectfolder&gt;/people/&lt;username&gt;/&lt;repositoryname&gt; and this is where you must keep all your files for the project.\nIf you cd into &lt;repositoryname&gt; and run ls, you will see a number of folders.\n\ndata: Stores small (tens of megabases) data files you want to keep .\nbinder: Stores the environment.yml files documenting your conda environment used in the project.\nsandbox: Stores experiment and other files that are not yet part of your project workflow. This keeps the rest of the folder structure clean.\nscripts: Stores Python scripts that that produces intermediate and final results.\nsteps: Stores intermediary files (“steps” on the way to final results).\nnotebooks: Stores Juptyer notebooks with code, documentation, and results.\nfigures: Stores result plots and figures you make.\nresults: Stores the small result files of your project (tens of megabases).\nreports: Stores documents reporting your findings.\n\nFiles in all those folders are under Git control, except files in the steps folder. Those files are not backed up in any way, but should instead be reproducible using the code and information in your other folders."
  },
  {
    "objectID": "guides/cluster_setup.html#git-101",
    "href": "guides/cluster_setup.html#git-101",
    "title": "3  Cluster set up",
    "section": "3.4 Git 101",
    "text": "3.4 Git 101\nWhen you are in your &lt;repositoryname&gt; folder, you can run git commands to manage your files, record their changes and sync them to the repository on GitHub for safe keeping. These tutorials are good introductions to git. The three most important commands to learn are: git status, git add, git rm, git mv, git commit and git push.\nYou use git add &lt;the_changed_file&gt; to journal the creation or modification of a file. This “stages” the change. This adds the file to the a “group” of changes that represent some modification to your project. You can add more files to that “group” by running git add again.\nMaybe you added or changed two python files that together lets you run some analysis. Now you want to store the group of changes to the journal maintained by Git and associate it with a description that describes it. For that you use git commit -m 'description'. If you added two python files, your description could be 'Added two python files for my analysis'. Now your changes are recorded in the version of the &lt;repositoryname&gt; on the cluster, but that does not serve as a backup in case you accidentally delete your entire folder or the cluster burns down. To backup your repository you need to synchronize your local &lt;repositoryname&gt; repository on your computer with the &lt;repositoryname&gt; repository on GitHub. You do that using the git push command.\nThere is a cheat sheet here and some good visual guides here and here.\n\n\n\n\n\n\nWarning: Files on the cluster are not backed up!\n\n\n\nYour files on the cluster are not backed up! If you want to backup files, you need to put them in a folder called BACKUP. But even if you do you may loose a week of work, since the backup loop is very slow.\n\n\nThe best/only way to keep your code safe is to track your files with git push each set of changes to GitHub as often as it makes sense. The more often you do it, the less work you will loose if you accidentally delete or overwrite a file.\nWe will get back to which files you should track using Git in Chapter 4 on how to to make your work reproducible."
  },
  {
    "objectID": "guides/cluster_setup.html#create-a-conda-environment",
    "href": "guides/cluster_setup.html#create-a-conda-environment",
    "title": "3  Cluster set up",
    "section": "3.5 Create a conda environment",
    "text": "3.5 Create a conda environment\nLog in to the cluster and run this command to create a conda environment for your project on the cluster. This environment should contain the packages that you need for your project.\nIf you create your environment like this (your can pick another name than birc-project if you have an environment with that name already):\nconda create -n birc-project -y -f binder/environment.yml\nThis environment contains most of the packages you will need. If you find yourself needing more packages than is initially included, you can easily install them later. E.g., to see how to install biopython using conda, just google “conda biopython”. The top link instructs you to install it like this: conda install -c conda-forge biopython.\nImportant: Whenever you log into the cluster to work on your project, you should activate your birc-project environment like this, otherwise the packages are not available:\nconda activate birc-project\nWhen your environment is active, it says (birc-project) on the command prompt instead of (base).\n\n3.5.1 Set up Jupyter\n\nJupyter is a notebook environment where you can easily combine text, code, and plots. Using the slurm-jupyter tool, you can run a jupyter notebook on the cluster but see it in the browser on your own machine. That way, your analysis runs on the cluster file system where your data is but the notebook interface is sent to your browser window.\nBefore you can connect to a jupyter session on the cluster, you need to do a bit of configuration of the jupyter settings on the cluster. slurm-jupyter comes with script that automates that procedure. Just log into the cluster, activate your environment, and run:\nconfig-slurm-jupyter.sh\nThe script will ask for a lot of information. You can just press Enter for all of them except when prompted for what password you want to use: Then, you must type your cluster password.\n\n\n3.5.2 How to run a Jupyter notebook on the cluster\nJupyter runs best in the Chrome browser or Safari on Mac. For the best experience, install that before you go on. It does not need to be your default browser. slurm-jupyter will use it anyway. Now make sure you are on your own machine and that your popgen environment is activated. Then run this command to start a jupyter notebook on the cluster and send the display to your browser:\nslurm-jupyter -C -u &lt;cluster_user_name&gt; -A &lt;projectfolder&lt;&gt; -e birc-project\n(replace &lt;cluster_user_name&gt; with your cluster user name, &lt;projectfolder&gt; with your project folder name.\nWatch the terminal to see what is going on. After a while, a jupyter notebook should show up in your browser window. The first time you do this, your browser may refuse to show jupyter because the connection is unsafe. In Safari you are prompted with this winidow where you click “details”:\n\nThen you get this window and click “visit this website”:\n\nIn Chrome, you can simply type the characters “thisisunsafe” while in the Chrome window:\n\nOnce ready, jupyter may ask for your cluster password. To close the jupyter notebook, press Ctrl-c in the terminal. Closing the browser window does not close down the jupyter on the cluster. You can read this tutorial to learn how to use a jupyter notebook.\n\n\n3.5.3 Visual Studio Code\n\nIf you did not do so when you installed Anaconda, you should download and install Visual Studio Code. VScode is great for developing scripts and editing text files. Once you have installed VScode, you should install the “Remote Development” extension. You do that by clicking the funny squares in the left bar and search for “Remote Development”. Once installed, you can click the small green square in the lower-left corner to connect to the cluster. Select “Connect current window to host” then “Add new SSH host”, then type &lt;username&gt;@login.genome.au.dk, then select the config file .ssh/config. Now you can click the small green square in the lower-left corner to connect to the cluster by selecting login.genome.au.dk. It may take a bit, but once it is done installing a remote server, you will have access to the files in your home folder on the cluster.\n\n\n3.5.4 Running interactive commands on the cluster\nWhen you log into the cluster, you land on the “front-end” of the cluster. Think of it as the lobby of a giant hotel. If you execute the hostname command, you will get fe-open-01. fe1 is the name of the front-end machine. The “front-end” is a single machine shared by anyone who logs in. So you cannot run resource-intensive jobs there, but quick commands are ok. Commands that finish in less than ten seconds are ok. In the exercises for this course, you will run software that takes a much longer time to finish. So you need one of the computing machines on the cluster, so you can work on that instead. You ask for a computing machine by running this command:\nsrun --mem-per-cpu=1g --time=3:00:00 --account=&lt;projectfolder&gt; --pty bash\nThat says that you need at most one gigabyte of memory, that you need it for at most three hours (the duration of the exercise), and that the computing expenses should be billed to the project &lt;projectfolder&gt;. When you execute the command, your terminal will say “srun: job 40924828 queued and waiting for resources”. That means that you are waiting for a machine. Once it prints “srun: job 40924828 has been allocated resources”, you have been logged into a computing node. If you execute the hostname command, you will get something like s05n20. s05n20 is a computing machine. The same way you moved from your own computer to front-end machine of the cluster by logging in using ssh, the command above moves you from the front-end to a compute machine. Now you can execute any command you like without causing trouble for anyone.\nNow try to log out of the compute node by executing the exit command or by pressing Ctrl-d. If you execute the hostname command again, you will get fe1.genomedk.net showing that you are back at the front-end machine.\n\n\n3.5.5 Queueing commands on the cluster\nFor non-interactive work, it is better to submit your command as a job to the cluster. When you do that, the job gets queued along with many other jobs, and as soon as the requested resources are available on the cluster, the job will start on one the many many machines. To submit a job, you must first create a file (a “batch script”) that contains both the requested computer resources and the command you want to run.\nCreate a file called myscript.sh with exactly this content:\n#!/bin/bash\n#SBATCH --mem=1gb\n#SBATCH --time=01:00:00\n#SBATCH --account=&lt;projectfolder&gt;\n#SBATCH --job-name=firstjob\n\necho \"I can submit cluster jobs now!\" &gt; success.txt\n(replace &lt;projectfolder&gt; with your project folder name)\nThe first line says this is a bash script, the lines following three lines say that your job needs at most one gigabyte of memory, will run for at most one hour, that the expenses should be billed to the project &lt;projectfolder&gt;. The fourth line gives the name of the job. Here we have called it firstjob, but you should name it something sensible.\nYou submit the job using the sbatch command:\nsbatch myscript.sh\nNow your job is queued. Use the mj command to see what jobs you have queued or running. That will show something like this:\n                                                                        Alloc\nJob ID           Username Queue    Jobname    SessID NDS  S Elap Time   nodes\n---------------- -------- -------- ---------- ------ ---  - ----------  -----\n34745986         kmt      normal   firstjob       --   1  R 0-00:19:27  s03n56\nIf you want to cancel this job before it finishes, you can use the scancel command:\nscancel 34745986\nOnce your job finishes, it has created the file success.txt and written “I can submit cluster jobs now!” to it. So see that you can use the cat command:\ncat success.txt\nWhen you a program or script on the command line, it usually also prints some information in the terminal. When you run a job on the cluster there is no terminal to print to. Instead, this is written to two files that you can read when the job finishes. In this case, the fiels are called firstjob.stdout and firstjob.stderr. To see what is in them, you can use the cat command:\ncat firstjob.stdout\nand\ncat firstjob.stderr\nThat is basically it.\n\n\n3.5.6 How to copy files to and from the cluster\nYou may need to transfer files back and forth between your own machine and the cluster. To copy a file called file in a directory called dir on the cluster to the current folder on your own machine, you can use the scp command:\nscp &lt;cluster_user_name&gt;@login.genome.au.dk:dir/file .\nTo copy a file called file in the current folder on your own machine to a folder called dir on the cluster, you do this:\nscp ./file &lt;cluster_user_name&gt;@login.genome.au.dk:dir/"
  },
  {
    "objectID": "guides/reproducible.html#specify-raw-input-data",
    "href": "guides/reproducible.html#specify-raw-input-data",
    "title": "4  Reproducible work",
    "section": "4.1 Specify raw input data",
    "text": "4.1 Specify raw input data\nReport the location and version of the raw data that serve as input to your analysis. Make sure this data is “read only” so that onone accidentally modifies or deletes it. You can do that like this:\nchmod a=r important_input_file.txt\nor recursively for an entire folder:\nchmod -R a=r input_file_folder"
  },
  {
    "objectID": "guides/reproducible.html#define-dependencies",
    "href": "guides/reproducible.html#define-dependencies",
    "title": "4  Reproducible work",
    "section": "4.2 Define dependencies",
    "text": "4.2 Define dependencies\nEmploying tools like Conda define the dependencies of your of your project, ensuring that others can run the same code with the same dependencies.\nWhen you create your conda environment, and whenever you install new packages, you should update the environment.yml file in the binder directory. That way the specification of your environment is always up to date and allows anyone to create the conda environment required to run your analysis You do it by running this command:\nconda env export --from-history -f ./binder/environment.yml"
  },
  {
    "objectID": "guides/reproducible.html#use-version-control",
    "href": "guides/reproducible.html#use-version-control",
    "title": "4  Reproducible work",
    "section": "4.3 Use version control",
    "text": "4.3 Use version control\nUsing version control systems like Git to track changes to code and documentation over time. This helps in understanding the evolution of the research and facilitates collaboration. It also allows you to tag the the state of your repository upon publication, so you can keep working on it later without disrupting its state at publication.\nIn the world of data projects, there are three kinds of data files.\nType 1 files: Files representing the input to your project: sequencing reads, genomes, genotypes, etc. These are usually difficult or expensive to reproduce and once made they never change. They are often too large to fit on GitHub, so they are saved (and backed up) indefinitely on the cluster, and can be distributed upon request to other researchers that want to replicate your analysis. Often the data is only local copy of data also available in a public database. You can put such files in the data folder of your repository on the cluster, but unless they are very small, do not git add these files to Git control.\nType 2 files: Files representing your work and the results from the project: documentation, scripts, code, gwf workflows, notebooks, plots, tables, etc. These files are usually as small as they are precious and they are the ones you add to your Git repository and puth to GitHub every time you change them. These files are workflow.py, and files you put in the binder, scripts, notebooks, results, figures, and reports folders.\nType 3 files: Files representing intermediary steps to get from files of type 1 to files of type 2. These can be large and many and often most of the harddisk space consumed by your project. However, they are easily regenerated if your project is reproducible. So type 3 files need not be saved indefinitely and they should not be added to your Git repository. In fact, type 3 files should be deleted as soon as the project is finished. All such files must be put in the steps folder or in folders inside the steps folder. This way, removing all type 3 files is safely done by deleting the content of the steps folder."
  },
  {
    "objectID": "guides/reproducible.html#make-computatioal-steps-an-executable-workflow",
    "href": "guides/reproducible.html#make-computatioal-steps-an-executable-workflow",
    "title": "4  Reproducible work",
    "section": "4.4 Make computatioal steps an executable workflow",
    "text": "4.4 Make computatioal steps an executable workflow\nPipeline the steps of the computationally demanding part of your analysis in executable workflows using cluster workflow tools like GWF. This ensures that interdependent steps are run in the right order and rerun if necessary."
  },
  {
    "objectID": "guides/reproducible.html#make-your-analysis-executable",
    "href": "guides/reproducible.html#make-your-analysis-executable",
    "title": "4  Reproducible work",
    "section": "4.5 Make your analysis executable",
    "text": "4.5 Make your analysis executable\nUse Jupyter notebooks to assemble the code, ducumentation, and figures relevant to each part of your subsequent analysis. That way your analysis is what is produced by running your notebooks in order, no more, no less. placeholder notebooks in the notebooks folder\nname them so they sort lexicographically: 01_first_analysis.ipynb, 02_second_analysis.ipynb."
  },
  {
    "objectID": "guides/reproducible.html#make-your-reporting-executable",
    "href": "guides/reproducible.html#make-your-reporting-executable",
    "title": "4  Reproducible work",
    "section": "4.6 Make your reporting executable",
    "text": "4.6 Make your reporting executable\nCompile your manuscript and any supplementary ducumemnts by linking to figures and results in your notebooks. This is easily done using tools like Quarto\nMarkdown / Qmarkdown / Notebooks\nthe _quarto.yml file\nrendering\nat the project end set output-dir to docs, render the whole thing and add docs to repository"
  },
  {
    "objectID": "guides/reproducible.html#make-your-entire-project-publicly-available",
    "href": "guides/reproducible.html#make-your-entire-project-publicly-available",
    "title": "4  Reproducible work",
    "section": "4.7 Make your entire project publicly available",
    "text": "4.7 Make your entire project publicly available\nMaking your repository publically available on GitHub. In addition to the scientific reguirement, reproducibility allows anyone to benefit from and build upon your work, greatly increasing its value."
  },
  {
    "objectID": "guides/reproducible.html#reproducing-your-work",
    "href": "guides/reproducible.html#reproducing-your-work",
    "title": "4  Reproducible work",
    "section": "4.8 Reproducing your work",
    "text": "4.8 Reproducing your work\nIf you follow the steps above, reproducing your results would only entail the following steps:\n\nRetrieve the raw data in the specified version.\nClone your Git repository.\nCreate the conda environment from the environment.yml file.\nRun GWF workflow on a compute cluster for the computationally demanding parts of your analysis.\nRun the Jupyter notebooks in the specified order.\nRun Quarto on the resulting state of the repository to build the manuscript and supplementary information.\n\nBelow I will go over how to organize your project so that these steps also contribute to makeing your own life easier."
  },
  {
    "objectID": "notebooks/01_getting_started.html",
    "href": "notebooks/01_getting_started.html",
    "title": "9  Getting started",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nfrom matplotlib_inline.backend_inline import set_matplotlib_formats\n#set_matplotlib_formats('retina', 'png')\nset_matplotlib_formats('pdf', 'svg')\nimport seaborn as sns\nsns.set()\nsns.set_style(\"ticks\")\nimport random\n\n\nplt.plot([random.random() for i in range(100)]) ;\n\n\n\n\nFigure 9.1: Line plot of random points. bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla"
  },
  {
    "objectID": "notebooks/02_jupyter_and_quarto.html",
    "href": "notebooks/02_jupyter_and_quarto.html",
    "title": "10  Jupyter with Quarto",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nfrom matplotlib_inline.backend_inline import set_matplotlib_formats\n#set_matplotlib_formats('retina', 'png')\nset_matplotlib_formats('pdf', 'svg')\nimport seaborn as sns\nsns.set()\nsns.set_style(\"ticks\")\nimport random\n\n\nplt.scatter([random.random() for i in range(100)],\n            [random.random() for i in range(100)]) ;\n\n\n\n\nFigure 10.1: Scatter plot of random points"
  },
  {
    "objectID": "reports/manuscript.html#abstract",
    "href": "reports/manuscript.html#abstract",
    "title": "11  Manuscript",
    "section": "11.1 Abstract",
    "text": "11.1 Abstract\nbla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla"
  },
  {
    "objectID": "reports/manuscript.html#introduction",
    "href": "reports/manuscript.html#introduction",
    "title": "11  Manuscript",
    "section": "11.2 Introduction",
    "text": "11.2 Introduction\nbla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla"
  },
  {
    "objectID": "reports/manuscript.html#results",
    "href": "reports/manuscript.html#results",
    "title": "11  Manuscript",
    "section": "11.3 Results",
    "text": "11.3 Results\nbla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla (Figure 11.1).\n\n\n\n\n\n\nFigure 11.1: Line plot of random points. bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla\n\n\n\n\nSource: 01_getting_started.ipynb\nbla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla (Figure 11.2)\n\n\n\n\n\n\nFigure 11.2: Scatter plot of random points\n\n\n\n\nSource: 02_jupyter_and_quarto.ipynb"
  },
  {
    "objectID": "reports/manuscript.html#discussion",
    "href": "reports/manuscript.html#discussion",
    "title": "11  Manuscript",
    "section": "11.4 Discussion",
    "text": "11.4 Discussion\nbla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla"
  },
  {
    "objectID": "reports/manuscript.html#methods",
    "href": "reports/manuscript.html#methods",
    "title": "11  Manuscript",
    "section": "11.5 Methods",
    "text": "11.5 Methods\nbla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla bla"
  },
  {
    "objectID": "reports/supplementary.html",
    "href": "reports/supplementary.html",
    "title": "12  Supplementary info",
    "section": "",
    "text": "bla bla bla"
  }
]