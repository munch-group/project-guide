[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Project Guide",
    "section": "",
    "text": "Introduction\nThese pages serve as a source of practial information to get you started. The part called “Project setup”, take you though the steps to get you set up on your own machine and on our computing cluster. You should go through this part in the other it is listed and make sure you have succesfully completed each step before you go on.\nThe Quickstarts are introductions to the most important tools you will use.\nYou will end up producing a set of pages much like these, and the Notebooks and Reporting both serve as showcases and to give you an idea of how your own notebooks and reports will show once you get to that point."
  },
  {
    "objectID": "guides/laptop_setup.html",
    "href": "guides/laptop_setup.html",
    "title": "1  Laptop setup",
    "section": "",
    "text": "You will work on our computing cluster, but before we get there, we must get you properly set up on your machine.\n\n1.0.1 Install Python\nIf you have not done so already, you should install a distribution of Python called Anaconda. Anaconda is not only an easy way of installing Python on Windows, Mac, and Linux; it also comes with the conda package management system (more about that later). To install Anaconda, visit this page. When the download completes, you must follow the default installation.\n\n\n1.0.2 The Terminal\nThe programs you will use in the project are command-line applications. I.e., programs executed by writing their name and any arguments in a “terminal” rather than clicking on an icon and using a graphical user interface. Many different programs can serve as a terminal.\n\nIf you have a Windows machine, use the Anaconda Powershell Prompt (not the Anaconda Prompt and not the CMD). You installed Anaconda Powershell Prompt along with Anaconda Python.\nIf you have a Mac, the terminal you will use is called Terminal. The Terminal application is pre-installed on Mac.\n\nFrom now on, whenever I refer to the terminal, I mean Anaconda Powershell Prompt on Windows and Terminal on Mac. I will assume some familiarity with using a terminal and executing commands on the command line. If you have not used a terminal before, or if you are a bit rusty, you should run through this primer before you go on.\n\n\n1.0.3 Conda environments\n\nYou must install packages and programs for your analyses and pipelines. Sometimes, however, the packages you need for one project conflict with the ones you need for other projects you work on in parallel. Such conflicts seem like an unsolvable problem. Would it not be fantastic if you could create a small world insulated from the rest of your Anaconda installation? Then, that small world would only contain the packages you needed for a single project. If each project had its isolated world, then there would be no such conflicts.\nFortunately, a tool lets you do just that, and its name is Conda. Conda’s small worlds are called “environments,” and you can create as many as you like. You can then switch between them as you switch between your bioinformatics projects. Conda also downloads and installs the packages for you, ensuring that the packages you install in each environment are compatible. It even makes sure to install packages (dependencies) required by the packages you install. By creating an environment for each project, the libraries installed for each project do not interfere.\n\n\n1.0.4 Create a conda environment on your local machine\nWhen you install Anaconda or Miniconda, Conda makes a single base environment. It is called “base,” and this is why it says “(base)” at your terminal prompt. You need a conda environment for your project on your local machine. You can call it anything you like, but if you call it birc-project, it will match the rest of this tutorial. So do that.\nThe environment on your local machine only needs a few packages since it only connects you to the cluster. The command below creates a birc-project environment and installs the slurm-jupyter package from my conda channel:\nconda create -y -n birc-project -c kaspermunch slurm-jupyter\nTo activate the environment, use this command:\nconda activate birc-project\nNote how the environment name at your terminal prompt changes from (base) to (birc-project). To deactivate the environment, use this command:\nconda deactivate\nand the terminal prompt changes back to (base).\n\n\n1.0.5 VPN\nYou can only connect to the cluster on the University’s internal network. So you must be physically on campus or use the University’s VPN. To install VPN, follow the instructions on this page. Before you can use the VPN, you also need to enable two-step verification. You can see how to do that on the same page. If you are not physically on campus, you must activate your VPN before logging in to the cluster. Your password for the VPN is the same as the one you use to log on to access Blackboard."
  },
  {
    "objectID": "guides/cluster_access.html",
    "href": "guides/cluster_access.html",
    "title": "2  Cluster access",
    "section": "",
    "text": "The GenomeDK cluster is a huge collection of computers with a shared file system. You can find lots of helpful information about the cluster on their homepage beyond what I cover on these pages. The cluster does not have a screen or keyboard you can use, but by connecting to the cluster from your computer, you can create and edit files much like if they were on your laptop. These pages take you through the steps to connect and access the cluster.\n\n\n\n\n\n\nThis is not a leisure read\n\n\n\nMake sure you follow it to the letter. Do each step in order, and do not proceed until you have successfully completed each step.\n\n\nBelow, you will see something like &lt;cluster user name&gt; or &lt;project folder&gt;. Whenever you see something like that, you should replace everything, including &lt; and &gt;, with whatever it says. E.g., if your cluster user name is mike, you should replace &lt;cluster user name&gt; with mike.\nBefore you can begin, you need access to the cluster. The cluster is called GenomeDK and has its own website with lots of information and documentation. To get an account on the cluster, you must request one here. Below, &lt;username&gt; will represent your user name.\n\n2.0.1 Connecting to the cluster using ssh\n\nSSH is short for secure shell. A shell is the software that lets you run commands in your terminal window. The secure shell (SSH) allows you to log in to another computer to navigate the folders and run commands on that machine. So when you open your terminal window, your commands run on your local machine, but when you “ssh” (yes, it is a verb, too) into the cluster, your commands run on the cluster. Before you go on, try to run the command hostname in your terminal. You can see that it prints something that tells you that you are on your laptop.\nYou connect to the cluster from the terminal by executing the command below (remember to replace &lt;cluster user name&gt; with your actual cluster user name):\nssh &lt;cluster user name&gt;@login.genome.au.dk\nWhen you do, ssh prompts you for the password that goes with your cluster username (GenomeDK requires two-factor authentication and will sometimes ask you for a site key). Enter the password and press Enter. You are now in your home folder on the cluster. Your terminal looks the same as before, but it will print:\n  _____                                ______ _   __\n |  __ \\                               |  _  \\ | / /\n | |  \\/ ___ _ __   ___  _ __ ___   ___| | | | |/ /\n | | __ / _ \\ '_ \\ / _ \\| '_ ` _ \\ / _ \\ | | |    \\\n | |_\\ \\  __/ | | | (_) | | | | | |  __/ |/ /| |\\  \\\n  \\____/\\___|_| |_|\\___/|_| |_| |_|\\___|___/ \\_| \\_/\nIf you run the hostname command again, you can see that you are now on fe-open-01. Now log out of the cluster again by typing exit and Enter (or pressing Ctrl-d). You are now back on your laptop. Try hostname again and see the name of your computer.\nYou will need to log in to the cluster many times, so you should set up your SSH connection to the cluster so you can connect securely without typing the password every time. You do not need to know how this works, but if you are interested, here is roughly how:\n\n\n\n\n\n\nSSH keys\n\n\n\nFirstly, you have to understand what public/private encryption keys are. A private key is a very long, random sequence of bits. A private key is kept secret and never leaves your laptop. A public key is another string of bits that is a derivative of the private key. You can generate a unique public key from the private key but cannot get the private key from a public key: It is a one-way process. You can encrypt (or sign) any message using the public key, and it will only be possible to decrypt it using the private key. In other words, anyone with your public key can send you encrypted messages that only you will be able to read. So, if the cluster has your public key saved, it can authenticate you like this: The cluster sends your machine an encrypted message using your public key. Your laptop then decrypts the message using its private key and sends it back. The cluster then checks the decryption and logs you in.\n\n\nFirst, check if you have these two authentication files on your local machine (you can do so by running ls -a ~/.ssh in the terminal):\n~/.ssh/id_rsa\n~/.ssh/id_rsa.pub\nYou most likely do not. If so, you generate authentication keys with the command below. Just press Enter when prompted for a file in which to save the key. Do not enter a passphrase when prompted - just press enter:\nssh-keygen -t rsa\n\nNow use ssh to create a directory ~/.ssh on the cluster (assuming your username on the cluster is &lt;cluster user name&gt;). SSH will prompt you for your password.\nssh &lt;cluster user name&gt;@login.genome.au.dk mkdir -p .ssh\nFinally, append the public ssh key on your local machine to the file .ssh/authorized_keys on the cluster and enter your password (replace &lt;cluster user name&gt; with your cluster user name):\ncat ~/.ssh/id_rsa.pub | ssh username@login.genome.au.dk 'cat &gt;&gt; .ssh/authorized_keys'\nFrom now on, you can log into the cluster from your local machine without being prompted for a password.\nTry it:\nssh &lt;cluster user name&gt;@login.genome.au.dk\n(see, no password)."
  },
  {
    "objectID": "guides/cluster_setup.html#install-python-on-your-cluster-account",
    "href": "guides/cluster_setup.html#install-python-on-your-cluster-account",
    "title": "3  Cluster set up",
    "section": "3.1 Install Python on your cluster account",
    "text": "3.1 Install Python on your cluster account\nYou need to install miniconda (a minimal Anaconda version) in your cluster home dir. Log in to the cluster and run this command to download the miniconda install script:\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nThen use this command to download and install miniconda:\nbash Miniconda3-latest-Linux-x86_64.sh\nFollow the default installation, and say yes when it asks you if it should run conda init for you.\nNP: Now log out of the cluster and log back in. This is needed to make the conda command available to you."
  },
  {
    "objectID": "guides/cluster_setup.html#the-project-folder",
    "href": "guides/cluster_setup.html#the-project-folder",
    "title": "3  Cluster set up",
    "section": "3.2 The project folder",
    "text": "3.2 The project folder\nThe project folder is a folder that is set up on the cluster to hold your project. I use the placeholder &lt;projectfolder&gt; here, but it will be called something sensible like baboonadmixture.\nIt is accessible to only you and anyone else you collaborate with (such as your supervisor). The project folder is in your home directory and should hold the following subfolders:\n&lt;projectfolder&gt;\n    /data\n    /people\n        /&lt;username&gt;\n        /&lt;supervisor_username&gt;\nThe &lt;projectfolder&gt;/people/&lt;username&gt; is your domain. This is where you have all the files that relates to your project.\nThe name of the project folder is is also the name of the account that gets billed for the work on the cluster. When you run gwf, srun, sbatch or slurm-jupyter (see below) you must specify that project name using the -A or --account options (see below for more details on that)."
  },
  {
    "objectID": "guides/cluster_setup.html#make-a-git-repository-for-your-project",
    "href": "guides/cluster_setup.html#make-a-git-repository-for-your-project",
    "title": "3  Cluster set up",
    "section": "3.3 Make a Git repository for your project",
    "text": "3.3 Make a Git repository for your project\n\nGit is a version control tool that you use from the terminal. A folder under Git control is called a repository. Git does not interfere with your files and it does not save them. It lets you monitor the state of your files so you can easily see if any files are added, modified, or removed, and it allows you to (manually) maintain a record of what files where changes when, how, and for what reason.\n\nStart by creating your own github account if you do not have one already.\nFollow the instructions on this page to add ssh keys to GitHub.\nEmail me your GitHub username on so I can add you to the shared GitHub account for our research group. I will create a repository for you with scaffold of folders and with placeholder files that will get you started in the right way.\nWait for an email or notification and accept my inviation to the “munch-lab” GitHub organization and an email from me with the name of the repository I made for your project. On these pages, I will use &lt;repositoryname&gt; for the name of your repository.\nMake sure you are logged into your GitHub account and then go to the repository listing at the munch-lab organization on GitHub. Find the directory I made for you and have a look at what is in there. Leave it there for now.\n\n\n3.3.1 Cloning this git repository to the cluster\nStart logging into the cluster and run these two commands to let Git know who you are:\ngit config --global user.name \"&lt;Your GitHub user name&gt;\"\ngit config --global user.email &lt;your_email@whatever.com&gt;\nGo to your folder under the project folder (~/&lt;projectfolder&gt;/people/&lt;username&gt;). Once you are in that folder, you can “clone” your git repository from GitHub to the folder on the cluster.\ngit clone git@github.com:munch-lab/&lt;repositoryname&gt;.git\n(replace &lt;repositoryname&gt; with the actual name of your repository).\nYou now have a folder called &lt;projectfolder&gt;/people/&lt;username&gt;/&lt;repositoryname&gt; and this is where you must keep all your files for the project.\nIf you cd into &lt;repositoryname&gt; and run ls, you will see a number of folders.\n\ndata: Stores small (tens of megabases) data files you want to keep .\nbinder: Stores the environment.yml files documenting your conda environment used in the project.\nsandbox: Stores experiment and other files that are not yet part of your project workflow. This keeps the rest of the folder structure clean.\nscripts: Stores Python scripts that that produces intermediate and final results.\nsteps: Stores intermediary files (“steps” on the way to final results).\nnotebooks: Stores Juptyer notebooks with code, documentation, and results.\nfigures: Stores result plots and figures you make.\nresults: Stores the small result files of your project (tens of megabases).\nreports: Stores documents reporting your findings.\n\nFiles in all those folders are under Git control, except files in the steps folder. Those files are not backed up in any way, but should instead be reproducible using the code and information in your other folders.\n\n\n\n\n\n\nWarning: Files on the cluster are not backed up!\n\n\n\nYour files on the cluster are not backed up! If you want to backup files, you need to put them in a folder called BACKUP. But even if you do you may loose a week of work, since the backup loop is very slow.\n\n\nThe best way to keep your progress safe, is to ensure is reproducible and pushed to GitHub as often as it makes sense (at least onece a day). The more often you do it, the less work you will loose if you accidentally delete or overwrite a file. More about that in Chapter 4 and Chapter 5."
  },
  {
    "objectID": "guides/cluster_setup.html#create-a-conda-environment",
    "href": "guides/cluster_setup.html#create-a-conda-environment",
    "title": "3  Cluster set up",
    "section": "3.4 Create a conda environment",
    "text": "3.4 Create a conda environment\nLog in to the cluster. Here, we will be a little more through with the conda environment, since this is where you will be doing all your work.\nBegin by creating an empty environment like this (you can pick another name than birc-project if you have an environment with that name already):\nconda create -n birc-project\nNow activate the environmet\nconda activate &lt;name&gt;\nMake sure it now says (birc-project) and and not (base) at your terminal prompt.\nNow add channels to the environment (places to search for packagages). These will do for now (you can always add more later):\nconda config --env --append channels conda-forge\nconda config --env --append channels bioconda\nconda config --env --append channels gwforg\nconda config --env --append channels kaspermunch\nThen install the actual packages. The following command installs the basic packages you will need for typical Python-based data analysis project:\nconda install git gwf jupyterlab ipython seaborn statsmodels scipy gwf pytables\nIf your project use probabilistic programming with PyMC (if you are in doubt, it is not), you need to install these packages as well:\nconda install arviz pymc seaborn xarray bambi\n\nIf you prefer to use R for data analysis and plots, you should use the following two commands to add the r channel and install the basic R packages:\nconda config --env --append channels r\nconda install r-essentials rpy2\nExport it to the binder folder to document which packages your project depends on:\nconda env export --from-history &gt; binder/environment.yml\nImportant: Whenever you log into the cluster to work on your project, you should activate your birc-project environment like this, otherwise the packages are not available:\nconda activate birc-project\nWhen your environment is active, it says (birc-project) on the command prompt instead of (base).\n\n3.4.1 Set up Jupyter\n\nJupyter is a notebook environment where you can easily combine text, code, and plots. Using the slurm-jupyter tool, you can run a jupyter notebook on the cluster but see it in the browser on your own machine. That way, your analysis runs on the cluster file system where your data is but the notebook interface is sent to your browser window.\nBefore you can connect to a jupyter session on the cluster, you need to do a bit of configuration of the jupyter settings on the cluster. slurm-jupyter comes with script that automates that procedure. Just log into the cluster, activate your environment, and run:\nconfig-slurm-jupyter.sh\nThe script will ask for a lot of information. You can just press Enter for all of them except when prompted for what password you want to use: Then, you must type your cluster password.\n\n\n3.4.2 How to run a Jupyter notebook on the cluster\nJupyter runs best in the Chrome browser or Safari on Mac. For the best experience, install that before you go on. It does not need to be your default browser. slurm-jupyter will use it anyway. Now make sure you are on your own machine and that your popgen environment is activated. Then run this command to start a jupyter notebook on the cluster and send the display to your browser:\nslurm-jupyter -C -u &lt;cluster_user_name&gt; -A &lt;projectfolder&lt;&gt; -e birc-project\n(replace &lt;cluster_user_name&gt; with your cluster user name, &lt;projectfolder&gt; with your project folder name.\nWatch the terminal to see what is going on. After a while, a jupyter notebook should show up in your browser window. The first time you do this, your browser may refuse to show jupyter because the connection is unsafe. In Safari you are prompted with this winidow where you click “details”:\n\nThen you get this window and click “visit this website”:\n\nIn Chrome, you can simply type the characters “thisisunsafe” while in the Chrome window:\n\nOnce ready, jupyter may ask for your cluster password. To close the jupyter notebook, press Ctrl-c in the terminal. Closing the browser window does not close down the jupyter on the cluster. You can read this tutorial to learn how to use a jupyter notebook.\n\n\n3.4.3 Visual Studio Code\n\nIf you did not do so when you installed Anaconda, you should download and install Visual Studio Code. VScode is great for developing scripts and editing text files. Once you have installed VScode, you should install the “Remote Development” extension. You do that by clicking the funny squares in the left bar and search for “Remote Development”. Once installed, you can click the small green square in the lower-left corner to connect to the cluster. Select “Connect current window to host” then “Add new SSH host”, then type &lt;username&gt;@login.genome.au.dk, then select the config file .ssh/config. Now you can click the small green square in the lower-left corner to connect to the cluster by selecting login.genome.au.dk. It may take a bit, but once it is done installing a remote server, you will have access to the files in your home folder on the cluster.\n\n\n3.4.4 Running interactive commands on the cluster\nWhen you log into the cluster, you land on the “front-end” of the cluster. Think of it as the lobby of a giant hotel. If you execute the hostname command, you will get fe-open-01. fe1 is the name of the front-end machine. The “front-end” is a single machine shared by anyone who logs in. So you cannot run resource-intensive jobs there, but quick commands are ok. Commands that finish in less than ten seconds are ok. In the exercises for this course, you will run software that takes a much longer time to finish. So you need one of the computing machines on the cluster, so you can work on that instead. You ask for a computing machine by running this command:\nsrun --mem-per-cpu=1g --time=3:00:00 --account=&lt;projectfolder&gt; --pty bash\nThat says that you need at most one gigabyte of memory, that you need it for at most three hours (the duration of the exercise), and that the computing expenses should be billed to the project &lt;projectfolder&gt;. When you execute the command, your terminal will say “srun: job 40924828 queued and waiting for resources”. That means that you are waiting for a machine. Once it prints “srun: job 40924828 has been allocated resources”, you have been logged into a computing node. If you execute the hostname command, you will get something like s05n20. s05n20 is a computing machine. The same way you moved from your own computer to front-end machine of the cluster by logging in using ssh, the command above moves you from the front-end to a compute machine. Now you can execute any command you like without causing trouble for anyone.\nNow try to log out of the compute node by executing the exit command or by pressing Ctrl-d. If you execute the hostname command again, you will get fe1.genomedk.net showing that you are back at the front-end machine.\n\n\n3.4.5 Queueing commands on the cluster\nFor non-interactive work, it is better to submit your command as a job to the cluster. When you do that, the job gets queued along with many other jobs, and as soon as the requested resources are available on the cluster, the job will start on one the many many machines. To submit a job, you must first create a file (a “batch script”) that contains both the requested computer resources and the command you want to run.\nCreate a file called myscript.sh with exactly this content:\n#!/bin/bash\n#SBATCH --mem=1gb\n#SBATCH --time=01:00:00\n#SBATCH --account=&lt;projectfolder&gt;\n#SBATCH --job-name=firstjob\n\necho \"I can submit cluster jobs now!\" &gt; success.txt\n(replace &lt;projectfolder&gt; with your project folder name)\nThe first line says this is a bash script, the lines following three lines say that your job needs at most one gigabyte of memory, will run for at most one hour, that the expenses should be billed to the project &lt;projectfolder&gt;. The fourth line gives the name of the job. Here we have called it firstjob, but you should name it something sensible.\nYou submit the job using the sbatch command:\nsbatch myscript.sh\nNow your job is queued. Use the mj command to see what jobs you have queued or running. That will show something like this:\n                                                                        Alloc\nJob ID           Username Queue    Jobname    SessID NDS  S Elap Time   nodes\n---------------- -------- -------- ---------- ------ ---  - ----------  -----\n34745986         kmt      normal   firstjob       --   1  R 0-00:19:27  s03n56\nIf you want to cancel this job before it finishes, you can use the scancel command:\nscancel 34745986\nOnce your job finishes, it has created the file success.txt and written “I can submit cluster jobs now!” to it. So see that you can use the cat command:\ncat success.txt\nWhen you a program or script on the command line, it usually also prints some information in the terminal. When you run a job on the cluster there is no terminal to print to. Instead, this is written to two files that you can read when the job finishes. In this case, the fiels are called firstjob.stdout and firstjob.stderr. To see what is in them, you can use the cat command:\ncat firstjob.stdout\nand\ncat firstjob.stderr\nThat is basically it.\n\n\n3.4.6 How to copy files to and from the cluster\nYou may need to transfer files back and forth between your own machine and the cluster. To copy a file called file in a directory called dir on the cluster to the current folder on your own machine, you can use the scp command:\nscp &lt;cluster_user_name&gt;@login.genome.au.dk:dir/file .\nTo copy a file called file in the current folder on your own machine to a folder called dir on the cluster, you do this:\nscp ./file &lt;cluster_user_name&gt;@login.genome.au.dk:dir/"
  },
  {
    "objectID": "guides/reproducible.html#specify-raw-input-data",
    "href": "guides/reproducible.html#specify-raw-input-data",
    "title": "4  Reproducible work",
    "section": "4.1 Specify raw input data",
    "text": "4.1 Specify raw input data\nReport the location and version of the raw data that serve as input to your analysis. Make sure this data is “read only” so that onone accidentally modifies or deletes it. You can do that like this:\nchmod a=r important_input_file.txt\nor recursively for an entire folder:\nchmod -R a=r input_file_folder"
  },
  {
    "objectID": "guides/reproducible.html#define-dependencies",
    "href": "guides/reproducible.html#define-dependencies",
    "title": "4  Reproducible work",
    "section": "4.2 Define dependencies",
    "text": "4.2 Define dependencies\nEmploying tools like Conda define the dependencies of your of your project, ensuring that others can run the same code with the same dependencies.\nWhen you create your conda environment, and whenever you install new packages, you should update the environment.yml file in the binder directory. That way the specification of your environment is always up to date and allows anyone to create the conda environment required to run your analysis You do it by running this command:\nconda env export --from-history -f ./binder/environment.yml\nOnce your project is well underway and you have settled on the set of packages needed for your project, you can make your environment more stable (and thus reproducible) by creating the environment again, installing all the packages in one go. To do that, first create a test environment to make sure that your exported environment can actually be created (you do not want to end up with a new environmnet that does not work like the old one):\nconda env create -n test -f binder/environment.yml\nIf, and only if, the test environment is successfully created and works the way it should you delete the test environment and the birc-project enrivonemnt:\nconda env remove -n test\nconda env remove -n birc-project\nand create a new version of the birc-project enrivonemnt:\nconda env create -f binder/environment.yml\nThen, to make life easier for someone reproducing your project on the GenomeDK, you must run this command as well (it records all the packages used including their linux versions used here):\nconda activate birc-project\nconda env export -f ./binder/environment-genomedk.yml"
  },
  {
    "objectID": "guides/reproducible.html#use-version-control",
    "href": "guides/reproducible.html#use-version-control",
    "title": "4  Reproducible work",
    "section": "4.3 Use version control",
    "text": "4.3 Use version control\nUsing version control systems like Git to track changes to code and documentation over time. This helps in understanding the evolution of the research and facilitates collaboration. It also allows you to tag the the state of your repository upon publication, so you can keep working on it later without disrupting its state at publication.\nIn the world of data projects, there are three kinds of data files.\nType 1 files: Files representing the input to your project: sequencing reads, genomes, genotypes, etc. These are usually difficult or expensive to reproduce and once made they never change. They are often too large to fit on GitHub, so they are saved (and backed up) indefinitely on the cluster, and can be distributed upon request to other researchers that want to replicate your analysis. Often the data is only local copy of data also available in a public database. You can put such files in the data folder of your repository on the cluster, but unless they are very small, do not git add these files to Git control.\nType 2 files: Files representing your work and the results from the project: documentation, scripts, code, gwf workflows, notebooks, plots, tables, etc. These files are usually as small as they are precious and they are the ones you add to your Git repository and puth to GitHub every time you change them. These files are workflow.py, and files you put in the binder, scripts, notebooks, results, figures, and reports folders.\nType 3 files: Files representing intermediary steps to get from files of type 1 to files of type 2. These can be large and many and often most of the harddisk space consumed by your project. However, they are easily regenerated if your project is reproducible. So type 3 files need not be saved indefinitely and they should not be added to your Git repository. In fact, type 3 files should be deleted as soon as the project is finished. All such files must be put in the steps folder or in folders inside the steps folder. This way, removing all type 3 files is safely done by deleting the content of the steps folder."
  },
  {
    "objectID": "guides/reproducible.html#make-computatioal-steps-an-executable-workflow",
    "href": "guides/reproducible.html#make-computatioal-steps-an-executable-workflow",
    "title": "4  Reproducible work",
    "section": "4.4 Make computatioal steps an executable workflow",
    "text": "4.4 Make computatioal steps an executable workflow\nPipeline the steps of the computationally demanding part of your analysis in executable workflows using cluster workflow tools like GWF. This ensures that interdependent steps are run in the right order and rerun if necessary."
  },
  {
    "objectID": "guides/reproducible.html#make-your-analysis-executable",
    "href": "guides/reproducible.html#make-your-analysis-executable",
    "title": "4  Reproducible work",
    "section": "4.5 Make your analysis executable",
    "text": "4.5 Make your analysis executable\nUse Jupyter notebooks to assemble the code, ducumentation, and figures relevant to each part of your subsequent analysis. That way your analysis is what is produced by running your notebooks in order, no more, no less. placeholder notebooks in the notebooks folder\nname them so they sort lexicographically: 01_first_analysis.ipynb, 02_second_analysis.ipynb."
  },
  {
    "objectID": "guides/reproducible.html#make-your-reporting-executable",
    "href": "guides/reproducible.html#make-your-reporting-executable",
    "title": "4  Reproducible work",
    "section": "4.6 Make your reporting executable",
    "text": "4.6 Make your reporting executable\nCompile your manuscript and any supplementary ducumemnts by linking to figures and results in your notebooks. This is easily done using tools like Quarto\nMarkdown / Qmarkdown / Notebooks\nthe _quarto.yml file\nrendering\nat the project end set output-dir to docs, render the whole thing and add docs to repository"
  },
  {
    "objectID": "guides/reproducible.html#make-your-entire-project-publicly-available",
    "href": "guides/reproducible.html#make-your-entire-project-publicly-available",
    "title": "4  Reproducible work",
    "section": "4.7 Make your entire project publicly available",
    "text": "4.7 Make your entire project publicly available\nMaking your repository publically available on GitHub. In addition to the scientific reguirement, reproducibility allows anyone to benefit from and build upon your work, greatly increasing its value."
  },
  {
    "objectID": "guides/reproducible.html#reproducing-your-work",
    "href": "guides/reproducible.html#reproducing-your-work",
    "title": "4  Reproducible work",
    "section": "4.8 Reproducing your work",
    "text": "4.8 Reproducing your work\nIf you follow the steps above, reproducing your results would only entail the following steps:\n\nRetrieve the raw data in the specified version.\nClone your Git repository.\nCreate the conda environment from the environment.yml file.\nRun GWF workflow on a compute cluster for the computationally demanding parts of your analysis.\nRun the Jupyter notebooks in the specified order.\nRun Quarto on the resulting state of the repository to build the manuscript and supplementary information.\n\nBelow I will go over how to organize your project so that these steps also contribute to makeing your own life easier."
  },
  {
    "objectID": "guides/git.html#git-as-journaled-backup",
    "href": "guides/git.html#git-as-journaled-backup",
    "title": "5  Git version control",
    "section": "5.1 Git as journaled backup",
    "text": "5.1 Git as journaled backup\nWhen you are in your &lt;repositoryname&gt; folder, you can run git commands to manage your files, record their changes and sync them to the repository on GitHub for safe keeping. These tutorials are good introductions to git.\nTo journal the creation or modification of a file, you need to add it to git:\ngit add &lt;the_changed_file&gt;\nThis “stages” the change. This adds the file to the a “group” of changes that represent some modification to your project. You can add more files to that “group” by running the command again with other files. If you run git status you can see that the files are now staged.\nSo maybe you added or changed two python files addressing some parcitular problem or advancing some part of your project. Now you want to store those of changes to the journal maintained by Git and associate it with a short message describing the changes. For that you use:\ngit commit -m '&lt;message&gt;'\nIf you added two python files, your description could be 'Added two python files for my analysis'. If you fixed a bug or added new code to the files, your message should reflect that.\nNow your changes are recorded in the version of the &lt;repositoryname&gt; on the cluster, but that does not serve as a backup in case you accidentally delete your entire folder or the cluster burns down. To backup your repository you need to synchronize your local &lt;repositoryname&gt; repository on the cluster with the &lt;repositoryname&gt; repository on GitHub. To du that use:\ngit push\nIn addition to keeping your precious files safe and backed up, your GitHub repository also serve as a journal documenting of your progress. Each commit is a snapshot if your project that can be retrieved at any time."
  },
  {
    "objectID": "guides/git.html#git",
    "href": "guides/git.html#git",
    "title": "5  Git version control",
    "section": "5.2 Git",
    "text": "5.2 Git\nThere is a cheat sheet here and some good visual guides here and here.\nThe three most important commands to learn are: git status, git add, git rm, git mv, git commit and git push."
  },
  {
    "objectID": "notebooks/00_jupyterlab.html",
    "href": "notebooks/00_jupyterlab.html",
    "title": "7  Jupyter lab",
    "section": "",
    "text": "8 Three kinds of cells\nCode cells: Cells with code, which any output below the cell:\nprint('hello world')\n\nhello world\nMarkdown cells: Cells with Markdown formatted text, which render in-place. So this\nsnippet of italic and bold text\nRaw cells: You can also make cells with raw/plain text, but that is not used much.\nThis is raw text\nOnce you get the hang of using notebooks, you will appreaciate keyboard shortcuts. You can see them with Shift-Cmd H on Mac, Shift-Ctrl H on Windows. There are two sets of shortcuts and you will see the ones relevant to the mode you are in. You are in “edit” when you are editing the content of cells. You can change to “command” mode by pressing `Ctrl-M’. If you view the shortcuts now, you get a different set relevant to other things that editing, like splitting, merging and copying cells.\nE.g., if I just made a new code cell and want to change it to a Markdown cell, I would press Ctrl-M for command mode and then M to change to Markdown. You will get the hang of it.\nNumpy arrays allow fast computation using vectors and matrices.\nAdding the values of two equal-sized lists in python might look something like this:\nlist1 = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nlist2 = [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n\nsummed = []\nfor i in range(len(list1)):\n    summed.append(list1[i] + list2[i])\nsummed\n\n[9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\nBut with arrays, you can broadcast operations across arrays like in R:\nimport numpy as np\na = np.array(list1)\nb = np.array(list2)\na, b\n\n(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([9, 8, 7, 6, 5, 4, 3, 2, 1, 0]))\na + b\n\narray([9, 9, 9, 9, 9, 9, 9, 9, 9, 9])\na * b\n\narray([ 0,  8, 14, 18, 20, 20, 18, 14,  8,  0])\na - 10\n\narray([-10,  -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1])\nArrays have lots of useful methods:\na.sum()\n\n45\na.mean()\n\n4.5\nIn python you can represent a matrix as a list of lists\nlist_of_lists = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nlist_of_lists\n\n[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nand index like this:\nlist_of_lists[1][1]\n\n5\nwith numpy, you can make multidimentional arrays:\nmatrix = np.array(list_of_lists)\nmatrix\n\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\nYou can still index them like this, but you should not:\nmatrix[1][1] # not efficient\n\n5\nThis is the correct and fast way:\nmatrix[1, 1] # efficient\n\n5\nbroadcasting and methods on multidimentional arrays:\nmatrix - 10\n\narray([[-9, -8, -7],\n       [-6, -5, -4],\n       [-3, -2, -1]])\nmatrix.sum()\n\n45\nYou can make arrays with as many dimentions you like:\nlist_of_lists_of_lists = [[[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[1, 2, 3], [4, 5, 6], [7, 8, 9]]]\nlist_of_lists_of_lists\n\n[[[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[1, 2, 3], [4, 5, 6], [7, 8, 9]]]\ntensor = np.array(list_of_lists_of_lists)\ntensor\n\narray([[[1, 2, 3],\n        [4, 5, 6],\n        [7, 8, 9]],\n\n       [[1, 2, 3],\n        [4, 5, 6],\n        [7, 8, 9]]])\ntensor[1, 1, 1]\n\n5\nFast computations on data tables (use numpy arrays internally).\nimport pandas as pd\n%config InlineBackend.figure_format = 'retina'\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\n\n# make graphics sharper on a good screen\nfrom matplotlib_inline.backend_inline import set_matplotlib_formats\nset_matplotlib_formats('retina', 'png')\nplt.scatter(penguins.bill_length_mm, penguins.flipper_length_mm) ;  # semi colon makes last value None\nsns.set_style(\"ticks\")\n# sns.set_style(\"darkgrid\")\n# sns.set_style(\"whitegrid\")\n# sns.set_style(\"white\")\n# sns.set_style(\"dark\")\n\nplt.scatter(penguins.bill_length_mm, penguins.flipper_length_mm)\nsns.despine()\nplt.hist(penguins.bill_length_mm) ;\nsns.scatterplot(data=penguins, x=\"bill_length_mm\", y=\"flipper_length_mm\") ;\nsns.scatterplot(data=penguins, x=\"bill_length_mm\", y=\"flipper_length_mm\", hue=\"species\") ;\nsns.scatterplot(data=penguins, x=\"bill_length_mm\", y=\"flipper_length_mm\", hue=\"species\", style=\"sex\") ;\nsns.scatterplot(data=penguins, x=\"bill_length_mm\", y=\"flipper_length_mm\", hue=\"species\", \n                style=\"sex\", size=\"body_mass_g\") ;\ndef legend_outside():\n    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0)\nsns.scatterplot(data=penguins, x=\"bill_length_mm\", y=\"flipper_length_mm\", hue=\"species\", style=\"sex\", size=\"body_mass_g\") ;\n\nlegend_outside()\n\nplt.title(\"Penguin measurements\")\nplt.ylabel(\"flipper length (mm)\")\nplt.xlabel(\"bill length in (mm)\") ;\nWide format data:\npenguins[['bill_length_mm', 'bill_depth_mm']]\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\n\n\n\n\n0\n39.1\n18.7\n\n\n1\n39.5\n17.4\n\n\n2\n40.3\n18.0\n\n\n3\nNaN\nNaN\n\n\n4\n36.7\n19.3\n\n\n...\n...\n...\n\n\n339\nNaN\nNaN\n\n\n340\n46.8\n14.3\n\n\n341\n50.4\n15.7\n\n\n342\n45.2\n14.8\n\n\n343\n49.9\n16.1\n\n\n\n\n344 rows × 2 columns\nLong format data:\nlong_df = penguins.melt(value_vars=['bill_length_mm', 'bill_depth_mm'])\nlong_df\n\n\n\n\n\n\n\n\nvariable\nvalue\n\n\n\n\n0\nbill_length_mm\n39.1\n\n\n1\nbill_length_mm\n39.5\n\n\n2\nbill_length_mm\n40.3\n\n\n3\nbill_length_mm\nNaN\n\n\n4\nbill_length_mm\n36.7\n\n\n...\n...\n...\n\n\n683\nbill_depth_mm\nNaN\n\n\n684\nbill_depth_mm\n14.3\n\n\n685\nbill_depth_mm\n15.7\n\n\n686\nbill_depth_mm\n14.8\n\n\n687\nbill_depth_mm\n16.1\n\n\n\n\n688 rows × 2 columns\nlong format is required when you want a number of columns to appear as a “variable” in the plot. As in the example below where the color “variable” reflects whether the point is bill_depth_mm or bill_length_mm.\nRetain other information for each observation:\nlong_df = penguins.melt(id_vars=['species', 'body_mass_g', 'island'], value_vars=['bill_length_mm', 'bill_depth_mm'])\nlong_df\n\n\n\n\n\n\n\n\nspecies\nbody_mass_g\nisland\nvariable\nvalue\n\n\n\n\n0\nAdelie\n3750.0\nTorgersen\nbill_length_mm\n39.1\n\n\n1\nAdelie\n3800.0\nTorgersen\nbill_length_mm\n39.5\n\n\n2\nAdelie\n3250.0\nTorgersen\nbill_length_mm\n40.3\n\n\n3\nAdelie\nNaN\nTorgersen\nbill_length_mm\nNaN\n\n\n4\nAdelie\n3450.0\nTorgersen\nbill_length_mm\n36.7\n\n\n...\n...\n...\n...\n...\n...\n\n\n683\nGentoo\nNaN\nBiscoe\nbill_depth_mm\nNaN\n\n\n684\nGentoo\n4850.0\nBiscoe\nbill_depth_mm\n14.3\n\n\n685\nGentoo\n5750.0\nBiscoe\nbill_depth_mm\n15.7\n\n\n686\nGentoo\n5200.0\nBiscoe\nbill_depth_mm\n14.8\n\n\n687\nGentoo\n5400.0\nBiscoe\nbill_depth_mm\n16.1\n\n\n\n\n688 rows × 5 columns\nsns.scatterplot(data=long_df, x='body_mass_g', y='value', hue='variable', style='species')\nlegend_outside()\nsns.boxplot(data=long_df, x='species', y='value', hue='variable') ;\nsns.boxplot(data=long_df, x='variable', y='value', hue='species') ;\nsns.boxplot(data=long_df, x='species', y='value', hue='variable') ;\ng = sns.FacetGrid(penguins, col=\"island\")\ng ;\nMap plotting to each facet:\ng = sns.FacetGrid(penguins, col=\"island\", hue=\"species\") ;\ng.map(sns.scatterplot, \"bill_length_mm\", \"flipper_length_mm\") ;\nGrid of facets representing combinations of two variables:\ng = sns.FacetGrid(penguins, row=\"sex\", col=\"island\", hue=\"species\") ;\ng.map(sns.scatterplot, \"bill_length_mm\", \"flipper_length_mm\") ;\ng = sns.FacetGrid(penguins, row=\"sex\", col=\"island\", hue=\"species\") ;\ng.map(sns.regplot, \"bill_length_mm\", \"flipper_length_mm\") ;\nsns.lmplot(data=penguins, x=\"bill_length_mm\", y=\"flipper_length_mm\", row=\"sex\", col=\"island\", hue=\"species\", height=3) ;\nimport matplotlib.pyplot as plt\nfrom matplotlib_inline.backend_inline import set_matplotlib_formats\n#set_matplotlib_formats('retina', 'png')\nset_matplotlib_formats('pdf', 'svg')\nimport seaborn as sns\nsns.set()\nsns.set_style(\"ticks\")\nimport random\nplt.scatter([random.random() for i in range(100)],\n            [random.random() for i in range(100)]) ;\n\n\n\n\nFigure 16.1: Scatter plot of random points"
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#starting-jupyter-lab",
    "href": "notebooks/00_jupyterlab.html#starting-jupyter-lab",
    "title": "7  Jupyter lab",
    "section": "7.1 Starting jupyter lab",
    "text": "7.1 Starting jupyter lab\nTerminal commands:\nconda activate &lt;environment&gt;\njupyter lab\nIt then appears in your default browser."
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#side-panes",
    "href": "notebooks/00_jupyterlab.html#side-panes",
    "title": "7  Jupyter lab",
    "section": "7.2 Side panes",
    "text": "7.2 Side panes\n\n\n\nScreenshot 2023-10-23 at 15.59.13.png\n\n\n\nFile and directory navigator.\nList of running notebooks/terminals.\nTable of content of active notebook.\n\n\n\n\n\n\n\nThis is a notebook\n\n\n\nWhat you are reading now is actually content rendered from a notebook. Once you clone your repository, you can see and experiment with the actual notebook. If you are viewing this in JupyterLab, try to open the table of content pane for an overview of the notebook (you can collapse the content groups)."
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#launching-a-new-notebook-or-terminal",
    "href": "notebooks/00_jupyterlab.html#launching-a-new-notebook-or-terminal",
    "title": "7  Jupyter lab",
    "section": "7.3 Launching a new notebook or terminal",
    "text": "7.3 Launching a new notebook or terminal\nClick the folder icon in the left side pane menu. Then click the big blue button with a + to launch a notebook, terminal or other."
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#views",
    "href": "notebooks/00_jupyterlab.html#views",
    "title": "7  Jupyter lab",
    "section": "7.4 Views",
    "text": "7.4 Views\nYou can resize the different windwos and panes by dragging their borders. Notebooks and terminals will appear in separate tabs. but you can drag tabs to the left/rigth/top/bottom of your main window to split the view and see more notebooks or terminals together."
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#controls",
    "href": "notebooks/00_jupyterlab.html#controls",
    "title": "7  Jupyter lab",
    "section": "7.5 Controls",
    "text": "7.5 Controls\n\nShared menu: At the top you find the regular menus like File, Edit, Run, etc. Look in the “Run” menu for running sections of the notebook or for restarting the notebook kernel (note that the menus often show the corresponding keyboard shortcuts).\nToolbar: At the top of each notebook there is a toolbar for cell operations (new, cut cell, copy cell, paste cell, run cell, ect.). You can always “hover” your curser over an icons to see what they do.\nCommand palette: Jupyter Lab has a command palette that you access with Shift-Cmd C on Mac, Shift-Ctrl C on Windows. Just start typing to find the command you want to execute."
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#executing-cells",
    "href": "notebooks/00_jupyterlab.html#executing-cells",
    "title": "7  Jupyter lab",
    "section": "8.1 Executing cells",
    "text": "8.1 Executing cells\nIn the the notebook toolbar there is a dropdown, where you can choose between Code, Markdown, and Raw for the current cell.\nTo execute/render a cell, you either press the “play” icon in the toolbar or press Cmd/Ctrl-Enter. To execute/render and go on to the next cell (usually what you do), press Shift-Enter.\nOnce executed, Mardown cells render in-place, showing the redered text instead of the Markdown code. To reveal/edit the Markdown text just double-click the cell.\nOnce executed, code displays show the value produced by the last statement in the cell, unless is it None (and any print statements):\nDisplays nothing:\n\nx = 0\n\nDisplays value of x:\n\nx = 1\nx\n\n1\n\n\nTo suppress display of last statement value, you can add a trailing ; (see later about plotting):\n\nx = 1\nx ;     # see, displays nothing below"
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#everything-is-one-python-process",
    "href": "notebooks/00_jupyterlab.html#everything-is-one-python-process",
    "title": "7  Jupyter lab",
    "section": "8.2 Everything is one Python process",
    "text": "8.2 Everything is one Python process\nWhat you are doing in a notebook is more like interactive Python than running a script. That means that running the same code more than once, or running cells in a different can produce different outcomes.\nMake an effort to write your notebooks in a way so they only work if executed in the manner you intend. One way to do that is to avoid using the same variable name for different purposes. In example below y should end up as 6, but if you run the x = \"banana\" cell again after the x = 3 cell, it ends up as 'bananabanana'.\n\nx = \"banana\"\n\n\nx = 3\n\n\ny = 2 * x\ny\n\n6\n\n\nIt is also good (and safe) style to make sure that running the same cell twice does not change its results:\n\nx = 0   # initializing x ensures that accidentally running the cell twice is not a problem\nx += 1\nx\n\n1"
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#shell-commands",
    "href": "notebooks/00_jupyterlab.html#shell-commands",
    "title": "7  Jupyter lab",
    "section": "8.3 Shell commands",
    "text": "8.3 Shell commands\nJupyter adds an extra feature that you do not otherwise have. Everythin after an ! in a code cell is interpreted as a shell command and executed:\n\n! ls\n\n00_jupyterlab.ipynb  02_interaction.ipynb\n01_weather.ipynb     README.md\n\n\nYou can even capture the output in a list like this:\n\nfiles_names = ! ls\nfiles_names\n\n['00_jupyterlab.ipynb',\n '01_weather.ipynb',\n '02_interaction.ipynb',\n 'README.md']"
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#interrupting-the-kernel",
    "href": "notebooks/00_jupyterlab.html#interrupting-the-kernel",
    "title": "7  Jupyter lab",
    "section": "8.4 Interrupting the kernel",
    "text": "8.4 Interrupting the kernel\nSometimes you may have executed some code that is taking a long time and needs to be aborted. To do that you click the “square” (stop) icon in the notebook toolbar."
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#restarting-the-kernel",
    "href": "notebooks/00_jupyterlab.html#restarting-the-kernel",
    "title": "7  Jupyter lab",
    "section": "8.5 Restarting the kernel",
    "text": "8.5 Restarting the kernel\nAlthough you try to avoid it, mistakes like the ones mentioned above happen. So when you sometimes it is good to restart the Python process (the kernel) and run all the cells in order, just to make sure it does what you thinik. You can do that by selecting “Restart Kernel and Run All Cells” from the “Run” menu."
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#markdown-text",
    "href": "notebooks/00_jupyterlab.html#markdown-text",
    "title": "7  Jupyter lab",
    "section": "8.6 Markdown text",
    "text": "8.6 Markdown text\n## Markdown text\n\nThis Markdown text is displays as the shown below. You can do **bold** and *italics*, show inline code, `x = 2 + 2`. You can show latex style formulas: \n\n$\\sum_{i=0}^n i$\n\nYou can make bullet lists:\n\n- foo\n- bar\n- baz\n\nnumbered lists:\n\n1. foo\n2. bar\n3. \n\nquotes:\n\n&gt; This is a quote\n\nand headers at different levels:\n\n##### Sub-sub-sub-sub header\n\n&lt;i&gt;and even use raw HTML&lt;/i&gt;\n\ntables:\n\n| Name  | Value |\n| :-----| :---- |\n| foo   | 1111  |\n| bar   | 0000  |\nThis Markdown text is produced from the code below. You can do bold and italics, show inline code, x = 2 + 2. You can show latex style formulas:\n\\(\\sum_{i=0}^n i\\)\nYou can make bullet lists:\n\nfoo\nbar\nbaz\n\nnumbered lists:\n\nfoo\nbar\n\n\nquotes:\n\nThis is a quote\n\nand headers at different levels:\n\n8.6.0.0.1 Sub-sub-sub-sub header\nand even use raw HTML\ntables:\n\n\n\nName\nValue\n\n\n\n\nfoo\n999\n\n\nbar\n1111"
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#html-magic",
    "href": "notebooks/00_jupyterlab.html#html-magic",
    "title": "7  Jupyter lab",
    "section": "8.7 HTML magic",
    "text": "8.7 HTML magic\nIf you need to execute some HTML code, you can make a code cell with the %%html magic on the first line. This sets fixed width numbers in tables so you can easily see how their magnitudes compare:\n\n%%html\n&lt;style&gt; table { font-variant-numeric: tabular-nums; } &lt;/style&gt;\n\n\n\n\n\n\n\n\nName\nValue\n\n\n\n\nfoo\n999\n\n\nbar\n1111"
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#images",
    "href": "notebooks/00_jupyterlab.html#images",
    "title": "7  Jupyter lab",
    "section": "8.8 Images",
    "text": "8.8 Images\nTo add and image, simply make a Markdown cell and drag an image into it."
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#moving-cells-around",
    "href": "notebooks/00_jupyterlab.html#moving-cells-around",
    "title": "7  Jupyter lab",
    "section": "8.9 Moving cells around",
    "text": "8.9 Moving cells around\nYou can move a cell by click-holding the left cell margin and dragging it to a new location. You can shift-click several cell margins to select more cells. The “Edit menu has commands for splitting a cell, merging cells, and much more."
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#two-kinds-of-undo",
    "href": "notebooks/00_jupyterlab.html#two-kinds-of-undo",
    "title": "7  Jupyter lab",
    "section": "8.10 Two kinds of Undo",
    "text": "8.10 Two kinds of Undo\n\nCell content undo: If you want to undo something you did to the content of a cell, you select the cell and either select “Undo” in the “Edit” menu.\nCell operation undo: If you want to undo something you did to some entire cells (E.g., cutting, pasting, moving or deleting cells), you either select “Undo Cell Operation” in the “Edit” menu."
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#dataframe",
    "href": "notebooks/00_jupyterlab.html#dataframe",
    "title": "7  Jupyter lab",
    "section": "11.1 DataFrame",
    "text": "11.1 DataFrame\nMake a dataframe from a dictionary:\n\ndf = pd.DataFrame({'name': ['Mike', 'Mia', 'Jake'], 'weight': [82, 62, 75]})\ndf\n\n\n\n\n\n\n\n\nname\nweight\n\n\n\n\n0\nMike\n82\n\n\n1\nMia\n62\n\n\n2\nJake\n75\n\n\n\n\n\n\n\n\ndf = pd.DataFrame(dict(name=['Mike', 'Mia', 'Jake'], weight=[82, 62, 75]))\ndf\n\n\n\n\n\n\n\n\nname\nweight\n\n\n\n\n0\nMike\n82\n\n\n1\nMia\n62\n\n\n2\nJake\n75\n\n\n\n\n\n\n\nMake a dataframe a list of tuples:\n\nrecords = [('Mike', 82), ('Mia', 62), ('Jake', 75)]\n\ndf = pd.DataFrame(records, columns=['name', 'weight'])\ndf\n\n\n\n\n\n\n\n\nname\nweight\n\n\n\n\n0\nMike\n82\n\n\n1\nMia\n62\n\n\n2\nJake\n75\n\n\n\n\n\n\n\nor even better:\n\ndf = pd.DataFrame().from_records(records, columns=['age', 'weight'])\ndf\n\n\n\n\n\n\n\n\nage\nweight\n\n\n\n\n0\nMike\n82\n\n\n1\nMia\n62\n\n\n2\nJake\n75\n\n\n\n\n\n\n\nYes, it is a dataframe object:\n\ntype(df)\n\npandas.core.frame.DataFrame\n\n\nDataframes have a row index:\n\ndf.index\n\nRangeIndex(start=0, stop=3, step=1)\n\n\n\ndf.index.values\n\narray([0, 1, 2])\n\n\nDataframes have columns with names:\n\ndf.columns\n\nIndex(['age', 'weight', 'height', 'sex'], dtype='object')\n\n\nData in each column can be of different type:\n\ndf.dtypes\n\nage         object\nweight       int64\nheight     float64\nsex       category\ndtype: object\n\n\nAdd a column to an existing dataframe:\n\ndf['height'] = [182.5, 173.0, 192.5]\ndf\n\n\n\n\n\n\n\n\nage\nweight\nheight\nsex\n\n\n\n\n0\nMike\n82\n182.5\nmale\n\n\n1\nMia\n62\n173.0\nfemale\n\n\n2\nJake\n75\n192.5\nmale\n\n\n\n\n\n\n\nAdd another, categorical, column:\n\ndf['sex'] = pd.Categorical(['male', 'female', 'male'], categories=['female', 'male'], ordered=True)\ndf\n\n\n\n\n\n\n\n\nage\nweight\nheight\nsex\n\n\n\n\n0\nMike\n82\n182.5\nmale\n\n\n1\nMia\n62\n173.0\nfemale\n\n\n2\nJake\n75\n192.5\nmale\n\n\n\n\n\n\n\n\ndf.dtypes\n\nage         object\nweight       int64\nheight     float64\nsex       category\ndtype: object\n\n\nYou can access individual columns as attributes:\n\ndf.height\n\n0    182.5\n1    173.0\n2    192.5\nName: height, dtype: float64\n\n\nor as keys:\n\ndf['height']\n\n0    182.5\n1    173.0\n2    192.5\nName: height, dtype: float64\n\n\nA column in a dataframe is a “Series”:\n\nsr = df.height\ntype(sr)\n\npandas.core.series.Series\n\n\nbut can easily turned into an array if need be:\n\nsr.to_numpy()\n\narray([182.5, 173. , 192.5])"
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#example-penguin-data-set",
    "href": "notebooks/00_jupyterlab.html#example-penguin-data-set",
    "title": "7  Jupyter lab",
    "section": "11.2 Example penguin data set",
    "text": "11.2 Example penguin data set\nBelow we load an example data set form the seaborn plotting library and show some of the most common uses of pandas:\n\nimport seaborn as sns\n\npenguins = sns.load_dataset('penguins')\n\n\npenguins\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nMale\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nFemale\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nFemale\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nFemale\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n339\nGentoo\nBiscoe\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n340\nGentoo\nBiscoe\n46.8\n14.3\n215.0\n4850.0\nFemale\n\n\n341\nGentoo\nBiscoe\n50.4\n15.7\n222.0\n5750.0\nMale\n\n\n342\nGentoo\nBiscoe\n45.2\n14.8\n212.0\n5200.0\nFemale\n\n\n343\nGentoo\nBiscoe\n49.9\n16.1\n213.0\n5400.0\nMale\n\n\n\n\n344 rows × 7 columns\n\n\n\n\npenguins.dtypes\n\nspecies               object\nisland                object\nbill_length_mm       float64\nbill_depth_mm        float64\nflipper_length_mm    float64\nbody_mass_g          float64\nsex                   object\ndtype: object\n\n\n\npenguins.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nMale\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nFemale\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nFemale\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nFemale\n\n\n\n\n\n\n\n\npenguins.tail()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\n\n\n339\nGentoo\nBiscoe\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n340\nGentoo\nBiscoe\n46.8\n14.3\n215.0\n4850.0\nFemale\n\n\n341\nGentoo\nBiscoe\n50.4\n15.7\n222.0\n5750.0\nMale\n\n\n342\nGentoo\nBiscoe\n45.2\n14.8\n212.0\n5200.0\nFemale\n\n\n343\nGentoo\nBiscoe\n49.9\n16.1\n213.0\n5400.0\nMale\n\n\n\n\n\n\n\nWrite it to a hdf5 file (in the current dir):\n\npenguins.to_hdf('penguins.h5', key='df', format='table')\n\nRead it back in from file:\n\npenguins = pd.read_hdf('penguins.h5')"
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#series",
    "href": "notebooks/00_jupyterlab.html#series",
    "title": "7  Jupyter lab",
    "section": "11.3 Series",
    "text": "11.3 Series\n\npenguins['flipper_length_mm']\n\n0      181.0\n1      186.0\n2      195.0\n3        NaN\n4      193.0\n       ...  \n339      NaN\n340    215.0\n341    222.0\n342    212.0\n343    213.0\nName: flipper_length_mm, Length: 344, dtype: float64\n\n\n\npenguins.flipper_length_mm\n\n0      181.0\n1      186.0\n2      195.0\n3        NaN\n4      193.0\n       ...  \n339      NaN\n340    215.0\n341    222.0\n342    212.0\n343    213.0\nName: flipper_length_mm, Length: 344, dtype: float64\n\n\n\ntype(penguins.flipper_length_mm)\n\npandas.core.series.Series"
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#broadcasting",
    "href": "notebooks/00_jupyterlab.html#broadcasting",
    "title": "7  Jupyter lab",
    "section": "11.4 Broadcasting",
    "text": "11.4 Broadcasting\n\npenguins.bill_depth_mm - 1000\n\n0     -981.3\n1     -982.6\n2     -982.0\n3        NaN\n4     -980.7\n       ...  \n339      NaN\n340   -985.7\n341   -984.3\n342   -985.2\n343   -983.9\nName: bill_depth_mm, Length: 344, dtype: float64\n\n\n\npenguins.bill_depth_mm * penguins.flipper_length_mm\n\n0      3384.7\n1      3236.4\n2      3510.0\n3         NaN\n4      3724.9\n        ...  \n339       NaN\n340    3074.5\n341    3485.4\n342    3137.6\n343    3429.3\nLength: 344, dtype: float64"
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#indexing",
    "href": "notebooks/00_jupyterlab.html#indexing",
    "title": "7  Jupyter lab",
    "section": "11.5 Indexing",
    "text": "11.5 Indexing\n\n11.5.1 Get a cell\n\npenguins.loc[4, 'island']\n\n'Torgersen'\n\n\n\n\n11.5.2 Get a row\n\npenguins.loc[4]\n\nspecies                 Adelie\nisland               Torgersen\nbill_length_mm            36.7\nbill_depth_mm             19.3\nflipper_length_mm        193.0\nbody_mass_g             3450.0\nsex                     Female\nName: 4, dtype: object\n\n\n\n\n11.5.3 Get a column\n\npenguins['bill_depth_mm']\n\n0      18.7\n1      17.4\n2      18.0\n3       NaN\n4      19.3\n       ... \n339     NaN\n340    14.3\n341    15.7\n342    14.8\n343    16.1\nName: bill_depth_mm, Length: 344, dtype: float64\n\n\n\npenguins.bill_depth_mm\n\n0      18.7\n1      17.4\n2      18.0\n3       NaN\n4      19.3\n       ... \n339     NaN\n340    14.3\n341    15.7\n342    14.8\n343    16.1\nName: bill_depth_mm, Length: 344, dtype: float64\n\n\n\n\n11.5.4 Get a range of rows and multiple columns\n\npenguins.loc[40:45, ['island', 'body_mass_g']]\n\n\n\n\n\n\n\n\nisland\nbody_mass_g\n\n\n\n\n40\nDream\n3150.0\n\n\n41\nDream\n3900.0\n\n\n42\nDream\n3100.0\n\n\n43\nDream\n4400.0\n\n\n44\nDream\n3000.0\n\n\n45\nDream\n4600.0\n\n\n\n\n\n\n\n\n\n11.5.5 Use boolean series as index to subset data\n\nidx = penguins.bill_length_mm &gt; 55\nidx\n\n0      False\n1      False\n2      False\n3      False\n4      False\n       ...  \n339    False\n340    False\n341    False\n342    False\n343    False\nName: bill_length_mm, Length: 344, dtype: bool\n\n\n\npenguins.loc[idx]\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\n\n\n169\nChinstrap\nDream\n58.0\n17.8\n181.0\n3700.0\nFemale\n\n\n215\nChinstrap\nDream\n55.8\n19.8\n207.0\n4000.0\nMale\n\n\n253\nGentoo\nBiscoe\n59.6\n17.0\n230.0\n6050.0\nMale\n\n\n321\nGentoo\nBiscoe\n55.9\n17.0\n228.0\n5600.0\nMale\n\n\n335\nGentoo\nBiscoe\n55.1\n16.0\n230.0\n5850.0\nMale\n\n\n\n\n\n\n\n\npenguins.loc[(penguins.bill_length_mm &gt; 55) & (penguins.sex == 'Female')]\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\n\n\n169\nChinstrap\nDream\n58.0\n17.8\n181.0\n3700.0\nFemale\n\n\n\n\n\n\n\n\n\n11.5.6 Setting and resetting the index\n\npenguins\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nMale\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nFemale\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nFemale\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nFemale\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n339\nGentoo\nBiscoe\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n340\nGentoo\nBiscoe\n46.8\n14.3\n215.0\n4850.0\nFemale\n\n\n341\nGentoo\nBiscoe\n50.4\n15.7\n222.0\n5750.0\nMale\n\n\n342\nGentoo\nBiscoe\n45.2\n14.8\n212.0\n5200.0\nFemale\n\n\n343\nGentoo\nBiscoe\n49.9\n16.1\n213.0\n5400.0\nMale\n\n\n\n\n344 rows × 7 columns\n\n\n\n\ndf = penguins.set_index(['species', 'sex', 'island'])\ndf.head(10)\n\n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\n\n\nspecies\nsex\nisland\n\n\n\n\n\n\n\n\nAdelie\nMale\nTorgersen\n39.1\n18.7\n181.0\n3750.0\n\n\nFemale\nTorgersen\n39.5\n17.4\n186.0\n3800.0\n\n\nTorgersen\n40.3\n18.0\n195.0\n3250.0\n\n\nNaN\nTorgersen\nNaN\nNaN\nNaN\nNaN\n\n\nFemale\nTorgersen\n36.7\n19.3\n193.0\n3450.0\n\n\nMale\nTorgersen\n39.3\n20.6\n190.0\n3650.0\n\n\nFemale\nTorgersen\n38.9\n17.8\n181.0\n3625.0\n\n\nMale\nTorgersen\n39.2\n19.6\n195.0\n4675.0\n\n\nNaN\nTorgersen\n34.1\n18.1\n193.0\n3475.0\n\n\nTorgersen\n42.0\n20.2\n190.0\n4250.0\n\n\n\n\n\n\n\n\ndf.reset_index()\n\n\n\n\n\n\n\n\nspecies\nsex\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\n\n\n\n\n0\nAdelie\nMale\nTorgersen\n39.1\n18.7\n181.0\n3750.0\n\n\n1\nAdelie\nFemale\nTorgersen\n39.5\n17.4\n186.0\n3800.0\n\n\n2\nAdelie\nFemale\nTorgersen\n40.3\n18.0\n195.0\n3250.0\n\n\n3\nAdelie\nNaN\nTorgersen\nNaN\nNaN\nNaN\nNaN\n\n\n4\nAdelie\nFemale\nTorgersen\n36.7\n19.3\n193.0\n3450.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n339\nGentoo\nNaN\nBiscoe\nNaN\nNaN\nNaN\nNaN\n\n\n340\nGentoo\nFemale\nBiscoe\n46.8\n14.3\n215.0\n4850.0\n\n\n341\nGentoo\nMale\nBiscoe\n50.4\n15.7\n222.0\n5750.0\n\n\n342\nGentoo\nFemale\nBiscoe\n45.2\n14.8\n212.0\n5200.0\n\n\n343\nGentoo\nMale\nBiscoe\n49.9\n16.1\n213.0\n5400.0\n\n\n\n\n344 rows × 7 columns"
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#sorting-rows",
    "href": "notebooks/00_jupyterlab.html#sorting-rows",
    "title": "7  Jupyter lab",
    "section": "11.6 Sorting rows",
    "text": "11.6 Sorting rows\n\nsorted_df = penguins.sort_values(by=\"bill_length_mm\")\nsorted_df.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\n\n\n\n\n142\nAdelie\nDream\n32.1\n15.5\n188.0\n3050.0\nFemale\n\n\n98\nAdelie\nDream\n33.1\n16.1\n178.0\n2900.0\nFemale\n\n\n70\nAdelie\nTorgersen\n33.5\n19.0\n190.0\n3600.0\nFemale\n\n\n92\nAdelie\nDream\n34.0\n17.1\n185.0\n3400.0\nFemale\n\n\n8\nAdelie\nTorgersen\n34.1\n18.1\n193.0\n3475.0\nNaN\n\n\n\n\n\n\n\n\nsorted_df.index.values\n\narray([142,  98,  70,  92,   8,  18,  54,  80,  14, 100,  52,  83, 124,\n        25,  66,  74, 136,  60,  90, 118,  68,  22,  42,  48, 150, 148,\n        78,  94, 120,  86,  34,  64,  58,  40,  15, 147,   4,  82, 132,\n        87,  44, 138,  77,  31, 144, 117,  84,  47, 133,  62,  38,  59,\n        21, 121, 102, 103,  10,  20,  11, 149, 104,  28,  96, 108, 134,\n       110, 107,  23,  88, 130,  13, 106, 116,  16,  24, 126,  36,  89,\n         6, 128, 145,  56,   0,  35, 146,   7,   5,  30,   1,  32, 114,\n        45,  50,  72,  93, 112, 105, 139,  71,  39,  51, 137, 140, 122,\n        97,   2,  27,  29, 125, 141,  26,  57, 143,  95,  41, 230, 182,\n        33,  76, 101, 135, 119,  46,  63,  91,  67,  12,  61,  85, 123,\n        55, 127, 151,  65, 326,  69, 236,  53,   9,  79, 113,  37,  49,\n       172, 184, 206,  17, 256, 115, 260,  75, 251,  81, 244, 131, 278,\n       109, 174,  99, 228, 328, 306, 216, 332, 288, 265, 276, 258, 129,\n        43, 257, 246, 336, 314, 268, 304, 275, 241, 252, 272, 208, 298,\n       299, 269, 342, 157, 280, 262, 226, 155, 232, 277, 195, 312, 266,\n       111, 211, 214, 204, 282,  73, 284, 234, 166, 160,  19, 158, 245,\n       220, 286, 238, 334, 281, 193, 243, 170, 180, 291, 294, 293, 225,\n       274, 152, 242, 162, 270, 227, 176, 325, 229, 340, 213, 317, 190,\n       164, 338, 322, 324, 250, 302, 310, 296, 187, 308, 188, 224, 290,\n       247, 329, 202, 248, 292, 318, 233, 255, 271, 173, 320, 295, 259,\n       239, 222, 337, 192, 199, 231, 300, 323, 254, 171, 237, 235, 209,\n       316, 313, 179, 287, 263, 261, 217, 186, 331, 201, 285, 343, 303,\n       153, 221, 223, 249, 198, 273, 210, 219, 240, 168, 279, 341, 267,\n       330, 167, 178, 264, 175, 289, 205, 305, 218, 197, 315, 196, 194,\n       185, 297, 319, 154, 159, 161, 307, 203, 333, 200, 163, 212, 165,\n       177, 189, 309, 207, 311, 301, 156, 181, 327, 191, 183, 283, 335,\n       215, 321, 169, 253,   3, 339])\n\n\nClick to the left of an output cell to enable/disable scrolling of the output (usefull for large amounts of output).\n\nsorted_df.loc[0]\n\nspecies                 Adelie\nisland               Torgersen\nbill_length_mm            39.1\nbill_depth_mm             18.7\nflipper_length_mm        181.0\nbody_mass_g             3750.0\nsex                       Male\nName: 0, dtype: object\n\n\n\nsorted_df.flipper_length_mm[0]\n\n181.0\n\n\n\nsorted_df.iloc[0] # iloc !!!\n\nspecies              Adelie\nisland                Dream\nbill_length_mm         32.1\nbill_depth_mm          15.5\nflipper_length_mm     188.0\nbody_mass_g          3050.0\nsex                  Female\nName: 142, dtype: object\n\n\n\nsorted_df.flipper_length_mm.iloc[0]\n\n188.0"
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#summary-stats",
    "href": "notebooks/00_jupyterlab.html#summary-stats",
    "title": "7  Jupyter lab",
    "section": "11.7 Summary stats",
    "text": "11.7 Summary stats\n\npenguins.describe()\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\n\n\n\n\ncount\n342.000000\n342.000000\n342.000000\n342.000000\n\n\nmean\n43.921930\n17.151170\n200.915205\n4201.754386\n\n\nstd\n5.459584\n1.974793\n14.061714\n801.954536\n\n\nmin\n32.100000\n13.100000\n172.000000\n2700.000000\n\n\n25%\n39.225000\n15.600000\n190.000000\n3550.000000\n\n\n50%\n44.450000\n17.300000\n197.000000\n4050.000000\n\n\n75%\n48.500000\n18.700000\n213.000000\n4750.000000\n\n\nmax\n59.600000\n21.500000\n231.000000\n6300.000000\n\n\n\n\n\n\n\n\npenguins.bill_length_mm.mean()\n\n43.9219298245614\n\n\n\npenguins.bill_length_mm.count()\n\n342"
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#grouping",
    "href": "notebooks/00_jupyterlab.html#grouping",
    "title": "7  Jupyter lab",
    "section": "11.8 Grouping",
    "text": "11.8 Grouping\n\npenguins.groupby('island')\n\n&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x15c85ab00&gt;\n\n\n\n11.8.1 Aggregate\nAggregating produces a single value for each variable in each group:\nMeans for all numeric variables for each island:\n\npenguins.groupby('island').aggregate(\"mean\", numeric_only=True)\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\n\n\nisland\n\n\n\n\n\n\n\n\nBiscoe\n45.257485\n15.874850\n209.706587\n4716.017964\n\n\nDream\n44.167742\n18.344355\n193.072581\n3712.903226\n\n\nTorgersen\n38.950980\n18.429412\n191.196078\n3706.372549\n\n\n\n\n\n\n\n\npenguins.groupby('island').mean(numeric_only=True)\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\n\n\nisland\n\n\n\n\n\n\n\n\nBiscoe\n45.257485\n15.874850\n209.706587\n4716.017964\n\n\nDream\n44.167742\n18.344355\n193.072581\n3712.903226\n\n\nTorgersen\n38.950980\n18.429412\n191.196078\n3706.372549\n\n\n\n\n\n\n\nMeans for bill_length_mm and flipper_length_mm:\n\npenguins.groupby('island')[['bill_length_mm', 'flipper_length_mm']].mean()\n\n\n\n\n\n\n\n\nbill_length_mm\nflipper_length_mm\n\n\nisland\n\n\n\n\n\n\nBiscoe\n45.257485\n209.706587\n\n\nDream\n44.167742\n193.072581\n\n\nTorgersen\n38.950980\n191.196078\n\n\n\n\n\n\n\nJust for flipper_length_mm:\n\npenguins.groupby('island').flipper_length_mm.mean()\n\nisland\nBiscoe       209.706587\nDream        193.072581\nTorgersen    191.196078\nName: flipper_length_mm, dtype: float64\n\n\n\n\n11.8.2 Transform\nTransforming produces new colums with the same length as the input:\n\npenguins.groupby('island')[['bill_length_mm', 'flipper_length_mm']].transform(\"mean\")\n\n\n\n\n\n\n\n\nbill_length_mm\nflipper_length_mm\n\n\n\n\n0\n38.950980\n191.196078\n\n\n1\n38.950980\n191.196078\n\n\n2\n38.950980\n191.196078\n\n\n3\n38.950980\n191.196078\n\n\n4\n38.950980\n191.196078\n\n\n...\n...\n...\n\n\n339\n45.257485\n209.706587\n\n\n340\n45.257485\n209.706587\n\n\n341\n45.257485\n209.706587\n\n\n342\n45.257485\n209.706587\n\n\n343\n45.257485\n209.706587\n\n\n\n\n344 rows × 2 columns\n\n\n\n\ndef z_value(sr):\n    return (sr - sr.mean()) / sr.std()\n\npenguins.groupby('island')[['bill_length_mm', 'flipper_length_mm']].transform(z_value)\n\n\n\n\n\n\n\n\nbill_length_mm\nflipper_length_mm\n\n\n\n\n0\n0.049258\n-1.636022\n\n\n1\n0.181475\n-0.833742\n\n\n2\n0.445910\n0.610362\n\n\n3\nNaN\nNaN\n\n\n4\n-0.744048\n0.289450\n\n\n...\n...\n...\n\n\n339\nNaN\nNaN\n\n\n340\n0.323193\n0.374297\n\n\n341\n1.077478\n0.869267\n\n\n342\n-0.012044\n0.162167\n\n\n343\n0.972717\n0.232877\n\n\n\n\n344 rows × 2 columns\n\n\n\n\n\n11.8.3 Apply\nFlexible method allowing any operation on grouped data.\nReturn a single value:\n\ndef fun(df):\n    return df.bill_length_mm + df.flipper_length_mm.mean() / df.body_mass_g\n\npenguins.groupby('island').apply(fun)#.to_frame('my_stat')\n\nisland        \nBiscoe     20     37.861678\n           21     37.758252\n           22     35.955186\n           23     38.253090\n           24     38.855186\n                    ...    \nTorgersen  127    41.544464\n           128    39.062687\n           129    44.147799\n           130    38.557503\n           131    43.154627\nLength: 344, dtype: float64\n\n\nReturn a dataframe:\n\ndef fun(df):\n    return pd.DataFrame({'sqrt_bill': np.sqrt(df.bill_length_mm),\n                         'bill_squared': df.bill_length_mm**2})\n\npenguins.groupby('island').apply(fun)\n\n\n\n\n\n\n\n\n\nsqrt_bill\nbill_squared\n\n\nisland\n\n\n\n\n\n\n\nBiscoe\n20\n6.148170\n1428.84\n\n\n21\n6.140033\n1421.29\n\n\n22\n5.991661\n1288.81\n\n\n23\n6.180615\n1459.24\n\n\n24\n6.228965\n1505.44\n\n\n...\n...\n...\n...\n\n\nTorgersen\n127\n6.442049\n1722.25\n\n\n128\n6.244998\n1521.00\n\n\n129\n6.640783\n1944.81\n\n\n130\n6.204837\n1482.25\n\n\n131\n6.565059\n1857.61\n\n\n\n\n344 rows × 2 columns"
  },
  {
    "objectID": "notebooks/00_jupyterlab.html#facetgrid.map-vs.-facetgrid.map_dataframe",
    "href": "notebooks/00_jupyterlab.html#facetgrid.map-vs.-facetgrid.map_dataframe",
    "title": "7  Jupyter lab",
    "section": "15.1 FacetGrid.map vs. FacetGrid.map_dataframe",
    "text": "15.1 FacetGrid.map vs. FacetGrid.map_dataframe\nWhen you use FacetGrid.map(func, \"col1\", \"col2\", ...), the function func is passed the values of the columns \"col1\" and \"col2\" (and more if needed) as parameters 1 and 2 (args[0], args[1], …). In addition, the function always receives a keyword argument named color=.\n\ndef scatter(*args, **kwargs):\n    return plt.scatter(args[0], args[1], **kwargs)\n    \ng = sns.FacetGrid(penguins, row=\"sex\", col=\"island\", hue=\"species\") ;\ng.map(scatter, \"bill_length_mm\", \"flipper_length_mm\") ;\n\n\n\n\nWhen you use FacetGrid.map_dataframe(func, \"col1\", \"col2\", ...), the function func is passed the names \"col1\" and \"col2\" (and more if needed) as parameters 1 and 2 (args[0], args[1], …), and the filtered dataframe as keyword argument data=. In addition, the function always receives a keyword argument named color=.\n\ndef scatterplot(*args, **kwargs):\n    return sns.scatterplot(x=args[0], y=args[1], **kwargs)\n\ng = sns.FacetGrid(penguins, row=\"sex\", col=\"island\", hue=\"species\") ;\ng.map_dataframe(scatterplot, \"bill_length_mm\", \"flipper_length_mm\") ;\n\n\n\n\n\ng = sns.FacetGrid(penguins, row=\"sex\", col=\"island\", hue=\"species\") ;\ng.map(sns.histplot, \"bill_length_mm\") ;\n\n\n\n\n\ng = sns.FacetGrid(penguins, row=\"sex\", col=\"island\", hue=\"species\") ;\ng.map(sns.kdeplot, \"bill_length_mm\") ;\n\n\n\n\n\nsns.pairplot(penguins, hue=\"species\") ;\n\n\n\n\n\nsns.pairplot(penguins, hue=\"sex\") ;"
  },
  {
    "objectID": "notebooks/01_weather.html#weather-data",
    "href": "notebooks/01_weather.html#weather-data",
    "title": "9  Danish weather",
    "section": "9.1 Weather data",
    "text": "9.1 Weather data\n\n\nWeather data was collected… blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah\n\n\n\nlong_format = df.melt(id_vars=['day'], value_vars=['wind', 'precipitation'], var_name='weather', value_name='value')\nlong_format\n\n\n\n\n\n\n\n\nday\nweather\nvalue\n\n\n\n\n0\n0\nwind\n1.707801\n\n\n1\n1\nwind\n1.677524\n\n\n2\n2\nwind\n1.219416\n\n\n3\n3\nwind\n1.952052\n\n\n4\n4\nwind\n1.733835\n\n\n...\n...\n...\n...\n\n\n295\n145\nprecipitation\n1.940254\n\n\n296\n146\nprecipitation\n1.216917\n\n\n297\n147\nprecipitation\n1.344908\n\n\n298\n148\nprecipitation\n1.746911\n\n\n299\n149\nprecipitation\n1.549489\n\n\n\n\n300 rows × 3 columns\n\n\n\n\nsns.lineplot(data=long_format, x='day', y='value', hue='weather')\nplt.ylim(bottom=0) ;\n\n\n\n\nFigure 9.1: Danish weather: This is the weather forcast for your project\n\n\n\n\nFrom this plot, it seems Danish weather is quite unpredictable."
  },
  {
    "objectID": "notebooks/02_interaction.html#sampling",
    "href": "notebooks/02_interaction.html#sampling",
    "title": "10  Workplace interaction",
    "section": "10.1 Sampling",
    "text": "10.1 Sampling\n\n\nI sampled 100 danaes from workplaces in Denmark. More about the sampling… blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah,\n\n\n\n\nWorkplace individuals were interviewed by …. blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah,\n\n\n\ndf = pd.DataFrame({'name': danish_people, \n                   'seniority': np.random.randint(0, 5, len(danish_people)), \n                   'age': np.random.randint(22, 67, len(danish_people))})\ndf['informality'] = np.random.normal(loc=10, scale=1, size=len(danish_people))\ndf\n\n\n\n\n\n\n\n\nname\nseniority\nage\ninformality\n\n\n\n\n0\nJulie\n4\n59\n10.577367\n\n\n1\nSofie\n0\n51\n9.456797\n\n\n2\nSara\n3\n57\n9.966668\n\n\n3\nCecilie\n3\n31\n10.806400\n\n\n4\nEmma\n1\n59\n9.494767\n\n\n...\n...\n...\n...\n...\n\n\n95\nJesper\n2\n44\n10.670476\n\n\n96\nDavid\n3\n48\n9.679540\n\n\n97\nAsger\n0\n40\n10.301785\n\n\n98\nMichael\n2\n45\n10.335186\n\n\n99\nJohan\n4\n33\n9.682334\n\n\n\n\n100 rows × 4 columns\n\n\n\n\nsns.scatterplot(x='age', y='informality', data=df, hue='seniority', palette='viridis')\nplt.ylabel('How informal you can be')\nplt.xlabel('Age')\nplt.legend(title='Seniority', loc='lower right', labels=['Undergrad', 'Postgrad', 'PhD', 'Postdoc', 'Professor'])\nplt.ylim(bottom=0) ;\n\n\n\n\nFigure 10.1: Interaction among Danes: How Danes interact is has very little to do with age and seniority, compared to most other contries.\n\n\n\n\nSeems Danish people act very informally unaffected by age and seniority.\n\ninformality_age_cor = df.informality.corr(df.age)\ninformality_age_cor\n\n-0.035287884645279835\n\n\n\ninformality_seniority_cor = df.informality.corr(df.seniority)\ninformality_seniority_cor\n\n0.05328570497075633\n\n\n\n\nThe correlation between informality and age was -0.035 and the correlation between informality and seniority was 0.053.\n\n\n\nsns.lmplot(x='age', y='informality', data=df, hue='seniority', palette='viridis')\nplt.ylabel('How informal you can be')\nplt.xlabel('Age') ;\n\n\n\n\nFigure 10.2: Interaction among Danes: Regressions of informality against age for five levels of seniority."
  },
  {
    "objectID": "reports/manuscript.html#abstract",
    "href": "reports/manuscript.html#abstract",
    "title": "11  Manuscript",
    "section": "11.1 Abstract",
    "text": "11.1 Abstract\nThis is my report about Denmark… blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah"
  },
  {
    "objectID": "reports/manuscript.html#introduction",
    "href": "reports/manuscript.html#introduction",
    "title": "11  Manuscript",
    "section": "11.2 Introduction",
    "text": "11.2 Introduction\nDenmark is …. blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah"
  },
  {
    "objectID": "reports/manuscript.html#results",
    "href": "reports/manuscript.html#results",
    "title": "11  Manuscript",
    "section": "11.3 Results",
    "text": "11.3 Results\n\n11.3.1 Weather\nAs shown in Figure 11.1, the Danish weather is blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah.\n\n\n\n\n\n\nFigure 11.1: Danish weather: This is the weather forcast for your project\n\n\n\n\nSource: 01_weather.ipynb\n\n\n11.3.2 Social norms\nIn Denmark, the workplace interaction is very informal and largely unaffected by seniority and age.\n\n\n\nI sampled 100 danaes from workplaces in Denmark. More about the sampling… blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah,\n\n\nSource: 02_interaction.ipynb\nI found that neither academic seniority or age of workplace individuals much affected how informal our interaction was (see Figure 11.2).\n\n\n\n\n\n\nFigure 11.2: Interaction among Danes: How Danes interact is has very little to do with age and seniority, compared to most other contries.\n\n\n\n\nSource: 02_interaction.ipynb\n\n\n\n\nThe correlation between informality and age was -0.035 and the correlation between informality and seniority was 0.053.\n\n\nSource: 02_interaction.ipynb"
  },
  {
    "objectID": "reports/manuscript.html#discussion",
    "href": "reports/manuscript.html#discussion",
    "title": "11  Manuscript",
    "section": "11.4 Discussion",
    "text": "11.4 Discussion\nThis this investigation of Danes…, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah."
  },
  {
    "objectID": "reports/manuscript.html#methods",
    "href": "reports/manuscript.html#methods",
    "title": "11  Manuscript",
    "section": "11.5 Methods",
    "text": "11.5 Methods\n\n11.5.1 Weather analysis\n\n\n\nWeather data was collected… blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah\n\n\nSource: 01_weather.ipynb\n\n\n11.5.2 Interaction analysis\n\n\n\nWorkplace individuals were interviewed by …. blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah,\n\n\nSource: 02_interaction.ipynb"
  },
  {
    "objectID": "reports/supplementary.html#regression-analysis-of-formality",
    "href": "reports/supplementary.html#regression-analysis-of-formality",
    "title": "12  Supplementary info",
    "section": "12.1 Regression analysis of formality",
    "text": "12.1 Regression analysis of formality\nBlah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah, blah.\n\n\n\n\n\n\nFigure 12.1: Interaction among Danes: Regressions of informality against age for five levels of seniority.\n\n\n\n\nSource: 02_interaction.ipynb"
  }
]